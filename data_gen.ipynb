{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ny[n] = exp(-i 2*pi*n*k/N) + w[n]\\nw[n] = a[n] + ib[n]\\nSNR = (1/(s^2))\\nSNRdB = 10*log10(SNR). \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "'''\n",
    "y[n] = exp(-i 2*pi*n*k/N) + w[n]\n",
    "w[n] = a[n] + ib[n]\n",
    "SNR = (1/(s^2))\n",
    "SNRdB = 10*log10(SNR). \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pure_signal(N, k):\n",
    "    return [np.exp(-1j * 2 * np.pi * k * n / N) for n in range(N)]\n",
    "\n",
    "def noisy_signal(N, k, SNRdB):\n",
    "    signal = pure_signal(N, k)\n",
    "    s = np.sqrt(1 / (10 ** (SNRdB / 10)))\n",
    "    a = np.random.randn(N) * s / np.sqrt(2)\n",
    "    b = np.random.randn(N)* s / np.sqrt(2)\n",
    "    noise = a + 1j*b\n",
    "    return signal + noise\n",
    "\n",
    "# returns tuple of m samples of noisy signals and chosen sampling indices\n",
    "def subsampled_noisy(N, k, SNRdB, m):\n",
    "    noisy_sig = noisy_signal(N, k, SNRdB)\n",
    "    chosen_indices = np.sort(np.random.choice(range(N), size=m, replace=False))\n",
    "    return (np.take(noisy_sig, chosen_indices), chosen_indices)\n",
    "\n",
    "def imag_to_pair(signal):\n",
    "    ret = []\n",
    "    for i in signal:\n",
    "        ret.append(np.round(np.real(i), 3))\n",
    "        ret.append(np.round(np.imag(i), 3))\n",
    "    return ret\n",
    "\n",
    "def one_hot(N, batch_size, freqs):\n",
    "    freqs_one_hot = np.zeros((batch_size, N))\n",
    "    freqs_one_hot[np.arange(batch_size), freqs] = 1\n",
    "    return freqs_one_hot\n",
    "\n",
    "def batch_pure(N, batch_size):\n",
    "    signals, freqs = [], []\n",
    "    for i in range(batch_size):\n",
    "        freq = np.random.randint(0, N)\n",
    "        signal = pure_signal(N, freq)\n",
    "        signals.append(imag_to_pair(signal))\n",
    "        freqs.append(freq)\n",
    "    return signals, one_hot(N, batch_size, freqs)\n",
    "\n",
    "def batch_noisy(N, SNRdB, batch_size):\n",
    "    signals, freqs = [], []\n",
    "    for i in range(batch_size):\n",
    "        freq = np.random.randint(0, N)\n",
    "        signal = noisy_signal(N, freq, SNRdB)\n",
    "        signals.append(imag_to_pair(signal))\n",
    "        freqs.append(freq)\n",
    "    return signals, one_hot(N, batch_size, freqs)\n",
    "        \n",
    "def batch_noisy_subsampled(N, SNRdB, m, batch_size):\n",
    "    signals, freqs, indices = [], [], []\n",
    "    for i in range(batch_size):\n",
    "        freq = np.random.randint(0, N)\n",
    "        signal, index = subsampled_noisy(N, freq, SNRdB, m)\n",
    "        signals.append(imag_to_pair(signal))\n",
    "        freqs.append(freq)\n",
    "        indices.append(index)\n",
    "    return signals, one_hot(N, batch_size, freqs), indices\n",
    "\n",
    "def batch_noisy_subsampled(N, SNRdB, m, batch_size, indices):\n",
    "    signals, freqs, repeated_ind = [], [], []\n",
    "    for i in range(batch_size):\n",
    "        freq = np.random.randint(0, N)\n",
    "        signal = noisy_signal(N, freq, SNRdB)\n",
    "        sub_signal = np.take(signal, indices)\n",
    "        signals.append(imag_to_pair(sub_signal))\n",
    "        freqs.append(freq)\n",
    "        repeated_ind.append(indices)\n",
    "    return signals, one_hot(N, batch_size, freqs), repeated_ind\n",
    "\n",
    "def batch_noisy_subsampled_raw(N, SNRdB, m, batch_size, indices):\n",
    "    signals, freqs, repeated_ind = [], [], []\n",
    "    for i in range(batch_size):\n",
    "        freq = np.random.randint(0, N)\n",
    "        signal = noisy_signal(N, freq, SNRdB)\n",
    "        sub_signal = np.take(signal, indices)\n",
    "        signals.append(imag_to_pair(sub_signal))\n",
    "        freqs.append([freq])\n",
    "        repeated_ind.append(indices)\n",
    "    return signals, freqs, repeated_ind\n",
    "\n",
    "def test_noisy_mle(N, signals, freqs):\n",
    "    count = 0\n",
    "    imag_signals = []    \n",
    "    for index in range(len(signals)):\n",
    "        sig = signals[index]\n",
    "        imag_sig = [(sig[i] + 1j*sig[i+1]) for i in np.arange(len(sig), step=2)]\n",
    "        imag_signals.append(imag_sig)\n",
    "                     \n",
    "    for index in range(len(signals)):\n",
    "        cleans = [pure_signal(N, i) for i in range(N)]\n",
    "        dots = [np.absolute(np.vdot(imag_signals[index], cleans[i])) for i in range(N)]\n",
    "        if np.argmax(freqs[index]) == np.argmax(dots):\n",
    "            count += 1\n",
    "    return count / len(freqs)\n",
    "\n",
    "def test_noisy_subsampled_mle(N, signals, freqs, indices):\n",
    "    count = 0\n",
    "    imag_signals = []    \n",
    "    for index in range(len(signals)):\n",
    "        sig = signals[index]\n",
    "        imag_sig = [(sig[i] + 1j*sig[i+1]) for i in np.arange(len(sig), step=2)]\n",
    "        imag_signals.append(imag_sig)\n",
    "                     \n",
    "    for index in range(len(signals)):\n",
    "        cleans = [np.take(pure_signal(N, i), indices[index]) for i in range(N)]\n",
    "        dots = [np.absolute(np.vdot(imag_signals[index], cleans[i])) for i in range(N)]\n",
    "        if np.argmax(freqs[index]) == np.argmax(dots):\n",
    "            count += 1\n",
    "    return count / len(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_signal(w,theta,n):\n",
    "    \"\"\"\n",
    "    Assumes normalized amplitude\n",
    "    \"\"\"\n",
    "    t = np.arange(n)\n",
    "    signal = np.exp(1j*(w*t + theta))\n",
    "    return signal\n",
    "\n",
    "def make_noise(sigma2,n):\n",
    "    noise_scaling = np.sqrt(sigma2/2)\n",
    "    # noise is complex valued\n",
    "    noise  = noise_scaling*np.random.randn(n) + 1j*noise_scaling*np.random.randn(n)\n",
    "    return noise\n",
    "\n",
    "def make_noisy_signal(w,theta,SNRdb,n):\n",
    "    sigma2 = get_sigma2_from_snrdb(SNRdb)\n",
    "    signal = make_signal(w,theta,n)\n",
    "    noise  = make_noise(sigma2,n)\n",
    "    return signal + noise\n",
    "\n",
    "# N = divisor of w0\n",
    "# m = num samples\n",
    "def make_batch_noisy(batch_size, SNRdb, N, m):\n",
    "    signals, freqs = [], []\n",
    "    for i in range(batch_size):\n",
    "        freq = np.random.randint(0, N)\n",
    "        w = (2 * np.pi * freq / N) % (2 * np.pi)\n",
    "        sig = make_noisy_signal(w, 0, SNRdb, m)\n",
    "        signals.append(sig)\n",
    "        freqs.append(freq)\n",
    "    return signals, one_hot(N, batch_size, freqs)\n",
    "\n",
    "def get_sigma2_from_snrdb(SNR_db):\n",
    "    return 10**(-SNR_db/10)\n",
    "\n",
    "def kay_weights(N):\n",
    "    scaling = (3.0/2)*N/(N**2 - 1)\n",
    "    \n",
    "    w = [1 - ((i - (N/2 - 1))/(N/2))**2 for i in range(N-1)]\n",
    "    \n",
    "    return scaling*np.array(w)\n",
    "\n",
    "def kays_method(my_signal):\n",
    "    N = len(my_signal)\n",
    "    w = kay_weights(N)\n",
    "    \n",
    "    angle_diff = np.angle(np.conj(my_signal[0:-1])*my_signal[1:])\n",
    "    need_to_shift = np.any(angle_diff < -np.pi/2)\n",
    "    if need_to_shift:    \n",
    "        neg_idx = angle_diff < 0\n",
    "        angle_diff[neg_idx] += np.pi*2\n",
    "    \n",
    "    return w.dot(angle_diff)\n",
    "\n",
    "def test_kays(signals, freqs, N):\n",
    "    count = 0\n",
    "    for sig, freq in zip(signals, freqs):\n",
    "        res = kays_method(sig)\n",
    "        res = round(res * N / (2 * np.pi))\n",
    "        if np.argmax(freq) == res:\n",
    "            count += 1\n",
    "    return count / len(signals)\n",
    "\n",
    "def test_mle(signals, freqs, N, m):\n",
    "    count = 0\n",
    "    for sig, freq in zip(signals, freqs):\n",
    "        cleans = [make_signal(np.pi * 2 * w / N, 0, m) for w in range(N)]\n",
    "        dots = [np.absolute(np.vdot(sig, clean)) for clean in cleans]\n",
    "        if np.argmax(dots) == np.argmax(freq):\n",
    "            count += 1\n",
    "    return count / len(signals)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snrs = [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\\nN = 512\\nm = 32\\naccs_kay, accs_mle = [], []\\nfor snr in snrs:\\n    sig, freq = make_batch_noisy(1000, snr, N, m)\\n    accs_kay.append(test_kays(sig, freq, N))\\n    accs_mle.append(test_mle(sig, freq, N, m))\\naccs2_kay, accs2_mle = [], []\\nsnr = 10\\nms = [128, 96, 64, 48, 32, 24, 16, 8]\\nfor currm in ms:\\n    sig, freq = make_batch_noisy(1000, snr, N, currm)\\n    accs2_kay.append(test_kays(sig, freq, N))\\n    accs2_mle.append(test_mle(sig, freq, N, currm))'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''snrs = [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
    "N = 512\n",
    "m = 32\n",
    "accs_kay, accs_mle = [], []\n",
    "for snr in snrs:\n",
    "    sig, freq = make_batch_noisy(1000, snr, N, m)\n",
    "    accs_kay.append(test_kays(sig, freq, N))\n",
    "    accs_mle.append(test_mle(sig, freq, N, m))\n",
    "accs2_kay, accs2_mle = [], []\n",
    "snr = 10\n",
    "ms = [128, 96, 64, 48, 32, 24, 16, 8]\n",
    "for currm in ms:\n",
    "    sig, freq = make_batch_noisy(1000, snr, N, currm)\n",
    "    accs2_kay.append(test_kays(sig, freq, N))\n",
    "    accs2_mle.append(test_mle(sig, freq, N, currm))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ea27907ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ea25ef1860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.load('./data/snr/snrs.npy'), np.load('./data/snr/kay.npy'), '--bo')\n",
    "plt.plot(np.load('./data/snr/snrs.npy'), np.load('./data/snr/mle.npy'), '--ro')\n",
    "plt.title('snr vs acc for kay at 32 samples')\n",
    "plt.show()\n",
    "plt.plot(np.load('./data/m/ms.npy'), np.load('./data/m/kay.npy'), '--bo')\n",
    "plt.plot(np.load('./data/m/ms.npy'), np.load('./data/m/mle.npy'), '--ro')\n",
    "plt.title('# samples vs acc for kay at snr=10db')\n",
    "plt.show()\n",
    "# 1000 samples foreach trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.76159418  0.76159418  0.96402758]\n",
      " [ 0.         -0.76159418  0.99505472]\n",
      " [ 0.76159418 -0.76159418  1.        ]\n",
      " [ 0.96402758  0.96402758  0.99505472]]\n"
     ]
    }
   ],
   "source": [
    "'''snr = -10\n",
    "N = 512\n",
    "m = 50\n",
    "num_trials = 1000\n",
    "count = 0\n",
    "for ind in range(num_trials):\n",
    "    k = np.random.randint(0, N)\n",
    "    noisy, indices = subsampled_noisy(N, k, snr, m)\n",
    "    cleans = [np.take(pure_signal(N, i), indices) for i in range(N)]\n",
    "    dots = [np.absolute(np.vdot(cleans[i], noisy)) for i in range(N)] \n",
    "    if k == np.argmax(dots):\n",
    "        count += 1\n",
    "print(count / num_trials)\n",
    "'''\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    a = [[-1.0, 1, 2], [0, -1, 3], [1,  -1, 10], [2, 2, 3]]\n",
    "    b = tf.tanh(a).eval()\n",
    "    print(b)\n",
    "a = [1, 2, 3]\n",
    "np.save('./data/a', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [14, 20, 28, 14, 14, 14, 20, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 100, Minibatch Loss= 514.5278, Training Accuracy= 0.047\n",
      "pred:  [14, 20, 28, 14, 14, 14, 28, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 200, Minibatch Loss= 457.7607, Training Accuracy= 0.047\n",
      "pred:  [14, 20, 28, 14, 14, 14, 28, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 300, Minibatch Loss= 409.7876, Training Accuracy= 0.047\n",
      "pred:  [14, 20, 28, 14, 14, 14, 28, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 400, Minibatch Loss= 368.9312, Training Accuracy= 0.031\n",
      "pred:  [14, 20, 28, 14, 14, 14, 28, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 500, Minibatch Loss= 334.1262, Training Accuracy= 0.031\n",
      "pred:  [14, 20, 28, 14, 14, 14, 16, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 600, Minibatch Loss= 304.3940, Training Accuracy= 0.031\n",
      "pred:  [14, 20, 28, 14, 14, 14, 19, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 700, Minibatch Loss= 278.0239, Training Accuracy= 0.031\n",
      "pred:  [14, 20, 28, 14, 14, 14, 19, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 800, Minibatch Loss= 254.5558, Training Accuracy= 0.031\n",
      "pred:  [14, 20, 28, 14, 14, 14, 11, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 900, Minibatch Loss= 234.1705, Training Accuracy= 0.062\n",
      "pred:  [16, 20, 28, 20, 17, 14, 11, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 1000, Minibatch Loss= 216.9659, Training Accuracy= 0.047\n",
      "pred:  [16, 20, 28, 20, 14, 14, 3, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 1100, Minibatch Loss= 201.6766, Training Accuracy= 0.031\n",
      "pred:  [16, 11, 28, 20, 14, 14, 3, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 1200, Minibatch Loss= 187.4227, Training Accuracy= 0.031\n",
      "pred:  [16, 31, 28, 20, 7, 14, 3, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 1300, Minibatch Loss= 174.3527, Training Accuracy= 0.031\n",
      "pred:  [16, 31, 28, 6, 7, 14, 3, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 1400, Minibatch Loss= 162.6914, Training Accuracy= 0.031\n",
      "pred:  [16, 31, 28, 6, 7, 13, 3, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 1500, Minibatch Loss= 152.0504, Training Accuracy= 0.031\n",
      "pred:  [16, 31, 28, 20, 7, 13, 3, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 1600, Minibatch Loss= 142.6889, Training Accuracy= 0.031\n",
      "pred:  [16, 31, 28, 20, 7, 13, 3, 14]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 1700, Minibatch Loss= 133.8953, Training Accuracy= 0.047\n",
      "pred:  [16, 31, 28, 6, 7, 13, 3, 15]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 1800, Minibatch Loss= 125.5948, Training Accuracy= 0.047\n",
      "pred:  [16, 31, 28, 6, 7, 13, 3, 15]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 1900, Minibatch Loss= 117.8970, Training Accuracy= 0.031\n",
      "pred:  [16, 31, 28, 6, 7, 13, 3, 15]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 2000, Minibatch Loss= 110.7542, Training Accuracy= 0.047\n",
      "pred:  [16, 31, 28, 20, 30, 13, 3, 15]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 2100, Minibatch Loss= 104.1443, Training Accuracy= 0.062\n",
      "pred:  [16, 31, 28, 6, 30, 13, 3, 22]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 2200, Minibatch Loss= 98.1893, Training Accuracy= 0.047\n",
      "pred:  [16, 31, 28, 6, 30, 13, 3, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 2300, Minibatch Loss= 92.7568, Training Accuracy= 0.047\n",
      "pred:  [16, 31, 28, 6, 30, 13, 3, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 2400, Minibatch Loss= 87.7766, Training Accuracy= 0.047\n",
      "pred:  [16, 31, 28, 6, 30, 13, 3, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 2500, Minibatch Loss= 83.0804, Training Accuracy= 0.047\n",
      "pred:  [16, 31, 28, 6, 30, 22, 3, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 2600, Minibatch Loss= 78.7496, Training Accuracy= 0.047\n",
      "pred:  [16, 31, 28, 6, 30, 22, 11, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 2700, Minibatch Loss= 74.6804, Training Accuracy= 0.062\n",
      "pred:  [16, 31, 28, 6, 30, 22, 11, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 2800, Minibatch Loss= 70.9699, Training Accuracy= 0.062\n",
      "pred:  [16, 31, 25, 6, 30, 22, 11, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 2900, Minibatch Loss= 67.6181, Training Accuracy= 0.031\n",
      "pred:  [16, 31, 25, 28, 30, 22, 11, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 3000, Minibatch Loss= 64.5072, Training Accuracy= 0.031\n",
      "pred:  [16, 30, 25, 6, 30, 13, 11, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 3100, Minibatch Loss= 61.3578, Training Accuracy= 0.047\n",
      "pred:  [16, 30, 25, 6, 30, 13, 11, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 3200, Minibatch Loss= 58.3147, Training Accuracy= 0.031\n",
      "pred:  [16, 30, 25, 6, 30, 13, 11, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 3300, Minibatch Loss= 55.2891, Training Accuracy= 0.047\n",
      "pred:  [16, 30, 25, 6, 30, 13, 11, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 3400, Minibatch Loss= 52.4041, Training Accuracy= 0.047\n",
      "pred:  [16, 30, 25, 6, 30, 13, 3, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 3500, Minibatch Loss= 49.7011, Training Accuracy= 0.047\n",
      "pred:  [16, 30, 25, 6, 30, 25, 3, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 3600, Minibatch Loss= 46.8936, Training Accuracy= 0.047\n",
      "pred:  [16, 30, 25, 14, 30, 25, 19, 5]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 3700, Minibatch Loss= 44.2519, Training Accuracy= 0.062\n",
      "pred:  [16, 31, 25, 14, 30, 25, 8, 5]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 3800, Minibatch Loss= 41.9792, Training Accuracy= 0.047\n",
      "pred:  [18, 31, 25, 6, 30, 25, 8, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 3900, Minibatch Loss= 39.9039, Training Accuracy= 0.031\n",
      "pred:  [18, 31, 25, 6, 30, 25, 8, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 4000, Minibatch Loss= 38.0980, Training Accuracy= 0.031\n",
      "pred:  [18, 30, 25, 6, 30, 25, 8, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 4100, Minibatch Loss= 36.3777, Training Accuracy= 0.031\n",
      "pred:  [18, 30, 25, 6, 30, 25, 8, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 4200, Minibatch Loss= 34.6944, Training Accuracy= 0.031\n",
      "pred:  [18, 30, 25, 6, 30, 25, 8, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 4300, Minibatch Loss= 33.0062, Training Accuracy= 0.047\n",
      "pred:  [18, 30, 25, 6, 30, 25, 8, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 4400, Minibatch Loss= 31.2577, Training Accuracy= 0.047\n",
      "pred:  [18, 30, 25, 6, 30, 25, 22, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 4500, Minibatch Loss= 29.4538, Training Accuracy= 0.047\n",
      "pred:  [18, 30, 25, 6, 30, 25, 22, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 4600, Minibatch Loss= 27.6638, Training Accuracy= 0.047\n",
      "pred:  [17, 30, 25, 14, 18, 25, 17, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 4700, Minibatch Loss= 25.9191, Training Accuracy= 0.047\n",
      "pred:  [17, 30, 20, 14, 18, 25, 17, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 4800, Minibatch Loss= 24.2750, Training Accuracy= 0.047\n",
      "pred:  [17, 30, 20, 14, 18, 25, 17, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 4900, Minibatch Loss= 22.6465, Training Accuracy= 0.047\n",
      "pred:  [17, 30, 20, 14, 12, 25, 17, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 5000, Minibatch Loss= 21.1189, Training Accuracy= 0.047\n",
      "pred:  [17, 30, 26, 14, 12, 25, 17, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 5100, Minibatch Loss= 19.4507, Training Accuracy= 0.047\n",
      "pred:  [20, 30, 20, 14, 12, 3, 3, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 5200, Minibatch Loss= 17.6960, Training Accuracy= 0.047\n",
      "pred:  [17, 30, 20, 14, 12, 3, 3, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 5300, Minibatch Loss= 15.9304, Training Accuracy= 0.062\n",
      "pred:  [17, 30, 20, 14, 12, 3, 9, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 5400, Minibatch Loss= 14.3408, Training Accuracy= 0.062\n",
      "pred:  [17, 30, 20, 14, 12, 3, 3, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 5500, Minibatch Loss= 12.9154, Training Accuracy= 0.031\n",
      "pred:  [17, 30, 20, 14, 13, 11, 11, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 5600, Minibatch Loss= 11.5708, Training Accuracy= 0.062\n",
      "pred:  [17, 30, 25, 28, 3, 11, 11, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 5700, Minibatch Loss= 10.2801, Training Accuracy= 0.094\n",
      "pred:  [13, 30, 25, 28, 3, 11, 4, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 5800, Minibatch Loss= 9.1946, Training Accuracy= 0.078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [13, 5, 24, 3, 3, 11, 4, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 5900, Minibatch Loss= 8.1347, Training Accuracy= 0.094\n",
      "pred:  [1, 5, 24, 3, 3, 11, 4, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 6000, Minibatch Loss= 7.0563, Training Accuracy= 0.094\n",
      "pred:  [4, 24, 24, 3, 3, 11, 9, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 6100, Minibatch Loss= 6.1402, Training Accuracy= 0.125\n",
      "pred:  [4, 24, 24, 28, 3, 11, 9, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 6200, Minibatch Loss= 5.5638, Training Accuracy= 0.125\n",
      "pred:  [22, 24, 24, 28, 20, 11, 9, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 6300, Minibatch Loss= 5.2384, Training Accuracy= 0.078\n",
      "pred:  [22, 24, 24, 28, 20, 11, 9, 4]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 6400, Minibatch Loss= 4.9609, Training Accuracy= 0.078\n",
      "pred:  [22, 24, 24, 28, 11, 11, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 6500, Minibatch Loss= 4.7233, Training Accuracy= 0.094\n",
      "pred:  [22, 27, 20, 6, 11, 11, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 6600, Minibatch Loss= 4.5352, Training Accuracy= 0.094\n",
      "pred:  [4, 27, 9, 6, 11, 11, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 6700, Minibatch Loss= 4.4240, Training Accuracy= 0.062\n",
      "pred:  [4, 27, 9, 19, 11, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 6800, Minibatch Loss= 4.3416, Training Accuracy= 0.062\n",
      "pred:  [9, 27, 9, 19, 11, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 6900, Minibatch Loss= 4.2756, Training Accuracy= 0.031\n",
      "pred:  [9, 27, 9, 19, 11, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 7000, Minibatch Loss= 4.2213, Training Accuracy= 0.031\n",
      "pred:  [9, 27, 9, 19, 11, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 7100, Minibatch Loss= 4.1778, Training Accuracy= 0.016\n",
      "pred:  [9, 27, 9, 19, 11, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 7200, Minibatch Loss= 4.1331, Training Accuracy= 0.016\n",
      "pred:  [9, 24, 9, 19, 11, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 7300, Minibatch Loss= 4.0867, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 19, 11, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 7400, Minibatch Loss= 4.0503, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 19, 11, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 7500, Minibatch Loss= 4.0138, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 7600, Minibatch Loss= 3.9816, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 7700, Minibatch Loss= 3.9445, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 7800, Minibatch Loss= 3.9074, Training Accuracy= 0.047\n",
      "pred:  [9, 24, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 7900, Minibatch Loss= 3.8774, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 8000, Minibatch Loss= 3.8540, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 8100, Minibatch Loss= 3.8351, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 8200, Minibatch Loss= 3.8198, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 8300, Minibatch Loss= 3.8069, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 8400, Minibatch Loss= 3.7956, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 8500, Minibatch Loss= 3.7858, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 8600, Minibatch Loss= 3.7788, Training Accuracy= 0.031\n",
      "pred:  [9, 24, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 8700, Minibatch Loss= 3.7723, Training Accuracy= 0.031\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 8800, Minibatch Loss= 3.7668, Training Accuracy= 0.031\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 8900, Minibatch Loss= 3.7611, Training Accuracy= 0.031\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 9000, Minibatch Loss= 3.7554, Training Accuracy= 0.031\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 9100, Minibatch Loss= 3.7499, Training Accuracy= 0.047\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 9200, Minibatch Loss= 3.7442, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 9300, Minibatch Loss= 3.7384, Training Accuracy= 0.062\n",
      "pred:  [19, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 9400, Minibatch Loss= 3.7308, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 9500, Minibatch Loss= 3.7216, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 9600, Minibatch Loss= 3.7110, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 9700, Minibatch Loss= 3.7040, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 9800, Minibatch Loss= 3.6972, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 9900, Minibatch Loss= 3.6905, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 10000, Minibatch Loss= 3.6845, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 10100, Minibatch Loss= 3.6789, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 10200, Minibatch Loss= 3.6735, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 10300, Minibatch Loss= 3.6684, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 10400, Minibatch Loss= 3.6630, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 10500, Minibatch Loss= 3.6585, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 10600, Minibatch Loss= 3.6540, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 10700, Minibatch Loss= 3.6494, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 10800, Minibatch Loss= 3.6454, Training Accuracy= 0.062\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 10900, Minibatch Loss= 3.6410, Training Accuracy= 0.078\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 11000, Minibatch Loss= 3.6370, Training Accuracy= 0.078\n",
      "pred:  [9, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 11100, Minibatch Loss= 3.6329, Training Accuracy= 0.078\n",
      "pred:  [22, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 11200, Minibatch Loss= 3.6286, Training Accuracy= 0.078\n",
      "pred:  [22, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 11300, Minibatch Loss= 3.6250, Training Accuracy= 0.078\n",
      "pred:  [22, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 11400, Minibatch Loss= 3.6218, Training Accuracy= 0.078\n",
      "pred:  [22, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 11500, Minibatch Loss= 3.6181, Training Accuracy= 0.078\n",
      "pred:  [22, 19, 9, 9, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 11600, Minibatch Loss= 3.6144, Training Accuracy= 0.078\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 11700, Minibatch Loss= 3.6112, Training Accuracy= 0.078\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 11800, Minibatch Loss= 3.6075, Training Accuracy= 0.078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 11900, Minibatch Loss= 3.6043, Training Accuracy= 0.078\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 12000, Minibatch Loss= 3.6005, Training Accuracy= 0.078\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 12100, Minibatch Loss= 3.5975, Training Accuracy= 0.078\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 12200, Minibatch Loss= 3.5941, Training Accuracy= 0.078\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 12300, Minibatch Loss= 3.5910, Training Accuracy= 0.062\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 12400, Minibatch Loss= 3.5876, Training Accuracy= 0.062\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 12500, Minibatch Loss= 3.5839, Training Accuracy= 0.062\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 12600, Minibatch Loss= 3.5803, Training Accuracy= 0.062\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 12700, Minibatch Loss= 3.5765, Training Accuracy= 0.062\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 12800, Minibatch Loss= 3.5729, Training Accuracy= 0.062\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 12900, Minibatch Loss= 3.5693, Training Accuracy= 0.062\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 13000, Minibatch Loss= 3.5662, Training Accuracy= 0.062\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 13100, Minibatch Loss= 3.5627, Training Accuracy= 0.062\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 13200, Minibatch Loss= 3.5596, Training Accuracy= 0.062\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 13300, Minibatch Loss= 3.5564, Training Accuracy= 0.062\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 13400, Minibatch Loss= 3.5534, Training Accuracy= 0.062\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 13500, Minibatch Loss= 3.5501, Training Accuracy= 0.078\n",
      "pred:  [22, 19, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 13600, Minibatch Loss= 3.5471, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 13700, Minibatch Loss= 3.5444, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 13800, Minibatch Loss= 3.5413, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 13900, Minibatch Loss= 3.5386, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 14000, Minibatch Loss= 3.5354, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 14100, Minibatch Loss= 3.5327, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 14200, Minibatch Loss= 3.5299, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 14300, Minibatch Loss= 3.5268, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 19, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 14400, Minibatch Loss= 3.5240, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 14500, Minibatch Loss= 3.5216, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 14600, Minibatch Loss= 3.5186, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 14700, Minibatch Loss= 3.5158, Training Accuracy= 0.062\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 14800, Minibatch Loss= 3.5162, Training Accuracy= 0.062\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 14900, Minibatch Loss= 3.5150, Training Accuracy= 0.062\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 15000, Minibatch Loss= 3.5132, Training Accuracy= 0.062\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 15100, Minibatch Loss= 3.5112, Training Accuracy= 0.062\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 15200, Minibatch Loss= 3.5088, Training Accuracy= 0.062\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 15300, Minibatch Loss= 3.5065, Training Accuracy= 0.062\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 15400, Minibatch Loss= 3.5044, Training Accuracy= 0.062\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 15500, Minibatch Loss= 3.5020, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 15600, Minibatch Loss= 3.4998, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 15700, Minibatch Loss= 3.4961, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 15800, Minibatch Loss= 3.4901, Training Accuracy= 0.078\n",
      "pred:  [22, 27, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 15900, Minibatch Loss= 3.4835, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 16000, Minibatch Loss= 3.4770, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 16100, Minibatch Loss= 3.4718, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 16200, Minibatch Loss= 3.4676, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 16300, Minibatch Loss= 3.4640, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 16400, Minibatch Loss= 3.4616, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 16500, Minibatch Loss= 3.4583, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 16600, Minibatch Loss= 3.4541, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 16700, Minibatch Loss= 3.4501, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 16800, Minibatch Loss= 3.4462, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 16900, Minibatch Loss= 3.4426, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 17000, Minibatch Loss= 3.4392, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 17100, Minibatch Loss= 3.4357, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 17200, Minibatch Loss= 3.4320, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 17300, Minibatch Loss= 3.4290, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 17400, Minibatch Loss= 3.4253, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 17500, Minibatch Loss= 3.4220, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 17600, Minibatch Loss= 3.4195, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 17700, Minibatch Loss= 3.4166, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 17800, Minibatch Loss= 3.4136, Training Accuracy= 0.078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 17900, Minibatch Loss= 3.4111, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 16, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 18000, Minibatch Loss= 3.4080, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 18100, Minibatch Loss= 3.4059, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 18200, Minibatch Loss= 3.4028, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 18300, Minibatch Loss= 3.4001, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 18400, Minibatch Loss= 3.3974, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 18500, Minibatch Loss= 3.3949, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 18600, Minibatch Loss= 3.3921, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 18700, Minibatch Loss= 3.3892, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 18800, Minibatch Loss= 3.3869, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 18900, Minibatch Loss= 3.3839, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 19000, Minibatch Loss= 3.3814, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 19100, Minibatch Loss= 3.3791, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 19200, Minibatch Loss= 3.3766, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 19300, Minibatch Loss= 3.3740, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 19400, Minibatch Loss= 3.3711, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 19500, Minibatch Loss= 3.3684, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 19600, Minibatch Loss= 3.3659, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 19700, Minibatch Loss= 3.3631, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 19800, Minibatch Loss= 3.3613, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 19900, Minibatch Loss= 3.3583, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 20000, Minibatch Loss= 3.3559, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 20100, Minibatch Loss= 3.3534, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 20200, Minibatch Loss= 3.3507, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 20300, Minibatch Loss= 3.3489, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 20400, Minibatch Loss= 3.3466, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 20500, Minibatch Loss= 3.3439, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 20600, Minibatch Loss= 3.3415, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 20700, Minibatch Loss= 3.3396, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 20800, Minibatch Loss= 3.3371, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 20900, Minibatch Loss= 3.3341, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 21000, Minibatch Loss= 3.3319, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 21100, Minibatch Loss= 3.3293, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 21200, Minibatch Loss= 3.3271, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 21300, Minibatch Loss= 3.3247, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 21400, Minibatch Loss= 3.3224, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 21500, Minibatch Loss= 3.3204, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 21600, Minibatch Loss= 3.3180, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 21700, Minibatch Loss= 3.3162, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 21800, Minibatch Loss= 3.3140, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 21900, Minibatch Loss= 3.3108, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 22000, Minibatch Loss= 3.3079, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 22100, Minibatch Loss= 3.3026, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 22200, Minibatch Loss= 3.2987, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 22300, Minibatch Loss= 3.2958, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 22400, Minibatch Loss= 3.2927, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 22500, Minibatch Loss= 3.2902, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 22600, Minibatch Loss= 3.2883, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 3, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 22700, Minibatch Loss= 3.2853, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 22800, Minibatch Loss= 3.2824, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 22900, Minibatch Loss= 3.2792, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 23000, Minibatch Loss= 3.2771, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 23100, Minibatch Loss= 3.2749, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 23200, Minibatch Loss= 3.2726, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 23300, Minibatch Loss= 3.2701, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 23400, Minibatch Loss= 3.2678, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 23500, Minibatch Loss= 3.2658, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 23600, Minibatch Loss= 3.2634, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 23700, Minibatch Loss= 3.2612, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 23800, Minibatch Loss= 3.2590, Training Accuracy= 0.062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 23900, Minibatch Loss= 3.2567, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 24000, Minibatch Loss= 3.2547, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 24100, Minibatch Loss= 3.2526, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 24200, Minibatch Loss= 3.2510, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 24300, Minibatch Loss= 3.2484, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 24400, Minibatch Loss= 3.2463, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 24500, Minibatch Loss= 3.2437, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 24600, Minibatch Loss= 3.2417, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 24700, Minibatch Loss= 3.2398, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 24800, Minibatch Loss= 3.2374, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 24900, Minibatch Loss= 3.2351, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 25000, Minibatch Loss= 3.2329, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 25100, Minibatch Loss= 3.2311, Training Accuracy= 0.062\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 25200, Minibatch Loss= 3.2291, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 25300, Minibatch Loss= 3.2271, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 25400, Minibatch Loss= 3.2249, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 25500, Minibatch Loss= 3.2230, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 25600, Minibatch Loss= 3.2212, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 25700, Minibatch Loss= 3.2194, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 25800, Minibatch Loss= 3.2174, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 25900, Minibatch Loss= 3.2151, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 26000, Minibatch Loss= 3.2138, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 26100, Minibatch Loss= 3.2120, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 26200, Minibatch Loss= 3.2103, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 26300, Minibatch Loss= 3.2088, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 26400, Minibatch Loss= 3.2073, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 26500, Minibatch Loss= 3.2058, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 26600, Minibatch Loss= 3.2040, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 26700, Minibatch Loss= 3.2026, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 26800, Minibatch Loss= 3.2011, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 26900, Minibatch Loss= 3.1995, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 27000, Minibatch Loss= 3.1977, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 27100, Minibatch Loss= 3.1964, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 27200, Minibatch Loss= 3.1944, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 27300, Minibatch Loss= 3.1930, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 27400, Minibatch Loss= 3.1915, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 27500, Minibatch Loss= 3.1899, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 27600, Minibatch Loss= 3.1884, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 27700, Minibatch Loss= 3.1870, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 27800, Minibatch Loss= 3.1858, Training Accuracy= 0.078\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 27900, Minibatch Loss= 3.1840, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 28000, Minibatch Loss= 3.1828, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 28100, Minibatch Loss= 3.1809, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 28200, Minibatch Loss= 3.1797, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 28300, Minibatch Loss= 3.1781, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 28400, Minibatch Loss= 3.1772, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 28500, Minibatch Loss= 3.1754, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 28600, Minibatch Loss= 3.1735, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 28700, Minibatch Loss= 3.1723, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 28800, Minibatch Loss= 3.1712, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 28900, Minibatch Loss= 3.1699, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 29000, Minibatch Loss= 3.1683, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 29100, Minibatch Loss= 3.1674, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 29200, Minibatch Loss= 3.1657, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 29300, Minibatch Loss= 3.1644, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 29400, Minibatch Loss= 3.1627, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 29500, Minibatch Loss= 3.1618, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 29600, Minibatch Loss= 3.1605, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 29700, Minibatch Loss= 3.1590, Training Accuracy= 0.094\n",
      "pred:  [22, 18, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 29800, Minibatch Loss= 3.1578, Training Accuracy= 0.094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 9, 4, 9, 9, 9, 9]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 29900, Minibatch Loss= 3.1565, Training Accuracy= 0.094\n",
      "pred:  [22, 31, 31, 4, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 30000, Minibatch Loss= 3.1552, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 4, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 30100, Minibatch Loss= 3.1542, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 30200, Minibatch Loss= 3.1530, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 30300, Minibatch Loss= 3.1518, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 4, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 30400, Minibatch Loss= 3.1505, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 30500, Minibatch Loss= 3.1491, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 4, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 30600, Minibatch Loss= 3.1483, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 30700, Minibatch Loss= 3.1471, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 30800, Minibatch Loss= 3.1453, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 30900, Minibatch Loss= 3.1440, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 31000, Minibatch Loss= 3.1438, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 31100, Minibatch Loss= 3.1424, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 31200, Minibatch Loss= 3.1412, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 31300, Minibatch Loss= 3.1398, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 31400, Minibatch Loss= 3.1387, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 4, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 31500, Minibatch Loss= 3.1375, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 31600, Minibatch Loss= 3.1366, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 31700, Minibatch Loss= 3.1359, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 31800, Minibatch Loss= 3.1344, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 31900, Minibatch Loss= 3.1336, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 32000, Minibatch Loss= 3.1320, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 32100, Minibatch Loss= 3.1313, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 32200, Minibatch Loss= 3.1298, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 32300, Minibatch Loss= 3.1289, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 32400, Minibatch Loss= 3.1279, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 32500, Minibatch Loss= 3.1269, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 32600, Minibatch Loss= 3.1263, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 32700, Minibatch Loss= 3.1258, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 32800, Minibatch Loss= 3.1253, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 32900, Minibatch Loss= 3.1244, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 33000, Minibatch Loss= 3.1238, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 33100, Minibatch Loss= 3.1229, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 33200, Minibatch Loss= 3.1220, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 33300, Minibatch Loss= 3.1208, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 33400, Minibatch Loss= 3.1200, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 33500, Minibatch Loss= 3.1190, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 33600, Minibatch Loss= 3.1181, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 33700, Minibatch Loss= 3.1172, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 33800, Minibatch Loss= 3.1164, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 33900, Minibatch Loss= 3.1154, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 34000, Minibatch Loss= 3.1144, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 34100, Minibatch Loss= 3.1138, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 34200, Minibatch Loss= 3.1127, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 34300, Minibatch Loss= 3.1116, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 34400, Minibatch Loss= 3.1109, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 34500, Minibatch Loss= 3.1101, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 34600, Minibatch Loss= 3.1092, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 34700, Minibatch Loss= 3.1083, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 34800, Minibatch Loss= 3.1078, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 34900, Minibatch Loss= 3.1068, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 35000, Minibatch Loss= 3.1058, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 35100, Minibatch Loss= 3.1052, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 35200, Minibatch Loss= 3.1043, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 35300, Minibatch Loss= 3.1033, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 35400, Minibatch Loss= 3.1027, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 35500, Minibatch Loss= 3.1018, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 35600, Minibatch Loss= 3.1011, Training Accuracy= 0.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 35700, Minibatch Loss= 3.1000, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 35800, Minibatch Loss= 3.0995, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 35900, Minibatch Loss= 3.0986, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 36000, Minibatch Loss= 3.0977, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 36100, Minibatch Loss= 3.0971, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 36200, Minibatch Loss= 3.0962, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 36300, Minibatch Loss= 3.0958, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 36400, Minibatch Loss= 3.0951, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 36500, Minibatch Loss= 3.0943, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 36600, Minibatch Loss= 3.0933, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 36700, Minibatch Loss= 3.0927, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 36800, Minibatch Loss= 3.0918, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 36900, Minibatch Loss= 3.0911, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 37000, Minibatch Loss= 3.0907, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 37100, Minibatch Loss= 3.0897, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 37200, Minibatch Loss= 3.0897, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 37300, Minibatch Loss= 3.0885, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 37400, Minibatch Loss= 3.0878, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 37500, Minibatch Loss= 3.0870, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 37600, Minibatch Loss= 3.0863, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 37700, Minibatch Loss= 3.0858, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 37800, Minibatch Loss= 3.0854, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 37900, Minibatch Loss= 3.0843, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 38000, Minibatch Loss= 3.0838, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 38100, Minibatch Loss= 3.0831, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 38200, Minibatch Loss= 3.0825, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 38300, Minibatch Loss= 3.0820, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 38400, Minibatch Loss= 3.0812, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 38500, Minibatch Loss= 3.0801, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 38600, Minibatch Loss= 3.0789, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 38700, Minibatch Loss= 3.0784, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 38800, Minibatch Loss= 3.0776, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 38900, Minibatch Loss= 3.0774, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 39000, Minibatch Loss= 3.0768, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 39100, Minibatch Loss= 3.0762, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 39200, Minibatch Loss= 3.0756, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 39300, Minibatch Loss= 3.0751, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 39400, Minibatch Loss= 3.0746, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 39500, Minibatch Loss= 3.0740, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 39600, Minibatch Loss= 3.0732, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 39700, Minibatch Loss= 3.0724, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 39800, Minibatch Loss= 3.0716, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 39900, Minibatch Loss= 3.0706, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 40000, Minibatch Loss= 3.0697, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 40100, Minibatch Loss= 3.0690, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 40200, Minibatch Loss= 3.0679, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 40300, Minibatch Loss= 3.0672, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 40400, Minibatch Loss= 3.0661, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 40500, Minibatch Loss= 3.0652, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 40600, Minibatch Loss= 3.0643, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 40700, Minibatch Loss= 3.0633, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 40800, Minibatch Loss= 3.0625, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 40900, Minibatch Loss= 3.0615, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 41000, Minibatch Loss= 3.0606, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 41100, Minibatch Loss= 3.0596, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 41200, Minibatch Loss= 3.0589, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 41300, Minibatch Loss= 3.0581, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 41400, Minibatch Loss= 3.0571, Training Accuracy= 0.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 41500, Minibatch Loss= 3.0565, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 41600, Minibatch Loss= 3.0556, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 31]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 41700, Minibatch Loss= 3.0547, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 41800, Minibatch Loss= 3.0552, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 41900, Minibatch Loss= 3.0542, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 42000, Minibatch Loss= 3.0534, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 42100, Minibatch Loss= 3.0524, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 42200, Minibatch Loss= 3.0516, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 42300, Minibatch Loss= 3.0509, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 42400, Minibatch Loss= 3.0503, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 42500, Minibatch Loss= 3.0493, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 42600, Minibatch Loss= 3.0485, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 42700, Minibatch Loss= 3.0478, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 42800, Minibatch Loss= 3.0470, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 42900, Minibatch Loss= 3.0461, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 43000, Minibatch Loss= 3.0455, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 43100, Minibatch Loss= 3.0444, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 43200, Minibatch Loss= 3.0437, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 43300, Minibatch Loss= 3.0423, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 43400, Minibatch Loss= 3.0413, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 43500, Minibatch Loss= 3.0402, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 43600, Minibatch Loss= 3.0391, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 43700, Minibatch Loss= 3.0379, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 43800, Minibatch Loss= 3.0369, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 43900, Minibatch Loss= 3.0355, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 44000, Minibatch Loss= 3.0343, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 44100, Minibatch Loss= 3.0330, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 44200, Minibatch Loss= 3.0313, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 44300, Minibatch Loss= 3.0316, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 44400, Minibatch Loss= 3.0310, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 44500, Minibatch Loss= 3.0303, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 44600, Minibatch Loss= 3.0296, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 44700, Minibatch Loss= 3.0287, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 44800, Minibatch Loss= 3.0280, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 44900, Minibatch Loss= 3.0272, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 45000, Minibatch Loss= 3.0266, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 45100, Minibatch Loss= 3.0257, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 45200, Minibatch Loss= 3.0249, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 45300, Minibatch Loss= 3.0243, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 45400, Minibatch Loss= 3.0236, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 45500, Minibatch Loss= 3.0230, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 45600, Minibatch Loss= 3.0223, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 45700, Minibatch Loss= 3.0215, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 45800, Minibatch Loss= 3.0208, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 45900, Minibatch Loss= 3.0201, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 46000, Minibatch Loss= 3.0194, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 46100, Minibatch Loss= 3.0187, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 46200, Minibatch Loss= 3.0180, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 46300, Minibatch Loss= 3.0173, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 46400, Minibatch Loss= 3.0166, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 46500, Minibatch Loss= 3.0159, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 46600, Minibatch Loss= 3.0152, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 46700, Minibatch Loss= 3.0146, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 46800, Minibatch Loss= 3.0138, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 46900, Minibatch Loss= 3.0133, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 47000, Minibatch Loss= 3.0126, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 47100, Minibatch Loss= 3.0120, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 47200, Minibatch Loss= 3.0114, Training Accuracy= 0.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 47300, Minibatch Loss= 3.0106, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 47400, Minibatch Loss= 3.0101, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 47500, Minibatch Loss= 3.0093, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 47600, Minibatch Loss= 3.0088, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 47700, Minibatch Loss= 3.0082, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 47800, Minibatch Loss= 3.0073, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 47900, Minibatch Loss= 3.0070, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 48000, Minibatch Loss= 3.0064, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 48100, Minibatch Loss= 3.0057, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 48200, Minibatch Loss= 3.0052, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 48300, Minibatch Loss= 3.0045, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 48400, Minibatch Loss= 3.0038, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 48500, Minibatch Loss= 3.0033, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 48600, Minibatch Loss= 3.0023, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 48700, Minibatch Loss= 3.0004, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 48800, Minibatch Loss= 2.9993, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 48900, Minibatch Loss= 2.9987, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 49000, Minibatch Loss= 2.9980, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 49100, Minibatch Loss= 2.9973, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 49200, Minibatch Loss= 2.9966, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 49300, Minibatch Loss= 2.9962, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 49400, Minibatch Loss= 2.9956, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 49500, Minibatch Loss= 2.9925, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 49600, Minibatch Loss= 2.9916, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 49700, Minibatch Loss= 2.9910, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 49800, Minibatch Loss= 2.9903, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 49900, Minibatch Loss= 2.9897, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 50000, Minibatch Loss= 2.9890, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 50100, Minibatch Loss= 2.9887, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 50200, Minibatch Loss= 2.9881, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 50300, Minibatch Loss= 2.9873, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 50400, Minibatch Loss= 2.9869, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 50500, Minibatch Loss= 2.9861, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 50600, Minibatch Loss= 2.9856, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 50700, Minibatch Loss= 2.9849, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 50800, Minibatch Loss= 2.9844, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 50900, Minibatch Loss= 2.9839, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 51000, Minibatch Loss= 2.9833, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 51100, Minibatch Loss= 2.9827, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 51200, Minibatch Loss= 2.9823, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 51300, Minibatch Loss= 2.9817, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 51400, Minibatch Loss= 2.9813, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 51500, Minibatch Loss= 2.9807, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 51600, Minibatch Loss= 2.9802, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 51700, Minibatch Loss= 2.9798, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 51800, Minibatch Loss= 2.9792, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 51900, Minibatch Loss= 2.9788, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 52000, Minibatch Loss= 2.9784, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 52100, Minibatch Loss= 2.9780, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 52200, Minibatch Loss= 2.9774, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 52300, Minibatch Loss= 2.9771, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 52400, Minibatch Loss= 2.9765, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 31, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 52500, Minibatch Loss= 2.9761, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 52600, Minibatch Loss= 2.9758, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 52700, Minibatch Loss= 2.9750, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 52800, Minibatch Loss= 2.9748, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 52900, Minibatch Loss= 2.9741, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 53000, Minibatch Loss= 2.9737, Training Accuracy= 0.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 53100, Minibatch Loss= 2.9734, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 53200, Minibatch Loss= 2.9728, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 53300, Minibatch Loss= 2.9723, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 53400, Minibatch Loss= 2.9718, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 53500, Minibatch Loss= 2.9714, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 53600, Minibatch Loss= 2.9710, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 53700, Minibatch Loss= 2.9702, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 53800, Minibatch Loss= 2.9700, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 53900, Minibatch Loss= 2.9694, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 54000, Minibatch Loss= 2.9690, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 54100, Minibatch Loss= 2.9685, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 54200, Minibatch Loss= 2.9680, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 3, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 54300, Minibatch Loss= 2.9674, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 54400, Minibatch Loss= 2.9670, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 54500, Minibatch Loss= 2.9665, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 54600, Minibatch Loss= 2.9661, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 54700, Minibatch Loss= 2.9655, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 54800, Minibatch Loss= 2.9652, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 54900, Minibatch Loss= 2.9645, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 55000, Minibatch Loss= 2.9642, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 55100, Minibatch Loss= 2.9637, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 55200, Minibatch Loss= 2.9632, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 55300, Minibatch Loss= 2.9627, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 55400, Minibatch Loss= 2.9624, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 55500, Minibatch Loss= 2.9618, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 55600, Minibatch Loss= 2.9615, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 55700, Minibatch Loss= 2.9609, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 55800, Minibatch Loss= 2.9605, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 55900, Minibatch Loss= 2.9597, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 56000, Minibatch Loss= 2.9595, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 56100, Minibatch Loss= 2.9590, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 56200, Minibatch Loss= 2.9585, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 56300, Minibatch Loss= 2.9580, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 56400, Minibatch Loss= 2.9577, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 56500, Minibatch Loss= 2.9572, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 56600, Minibatch Loss= 2.9570, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 56700, Minibatch Loss= 2.9561, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 56800, Minibatch Loss= 2.9560, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 56900, Minibatch Loss= 2.9555, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 57000, Minibatch Loss= 2.9550, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 57100, Minibatch Loss= 2.9545, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 57200, Minibatch Loss= 2.9542, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 57300, Minibatch Loss= 2.9537, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 57400, Minibatch Loss= 2.9531, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 57500, Minibatch Loss= 2.9527, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 57600, Minibatch Loss= 2.9524, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 57700, Minibatch Loss= 2.9521, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 57800, Minibatch Loss= 2.9515, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 57900, Minibatch Loss= 2.9507, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 58000, Minibatch Loss= 2.9505, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 58100, Minibatch Loss= 2.9501, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 58200, Minibatch Loss= 2.9496, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 58300, Minibatch Loss= 2.9493, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 58400, Minibatch Loss= 2.9488, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 58500, Minibatch Loss= 2.9483, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 58600, Minibatch Loss= 2.9480, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 58700, Minibatch Loss= 2.9474, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 58800, Minibatch Loss= 2.9469, Training Accuracy= 0.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 58900, Minibatch Loss= 2.9466, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 59000, Minibatch Loss= 2.9462, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 59100, Minibatch Loss= 2.9457, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 59200, Minibatch Loss= 2.9452, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 59300, Minibatch Loss= 2.9449, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 59400, Minibatch Loss= 2.9442, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 59500, Minibatch Loss= 2.9439, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 59600, Minibatch Loss= 2.9435, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 59700, Minibatch Loss= 2.9430, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 59800, Minibatch Loss= 2.9426, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 59900, Minibatch Loss= 2.9423, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 60000, Minibatch Loss= 2.9418, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 60100, Minibatch Loss= 2.9412, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 60200, Minibatch Loss= 2.9408, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 60300, Minibatch Loss= 2.9406, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 60400, Minibatch Loss= 2.9400, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 60500, Minibatch Loss= 2.9398, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 60600, Minibatch Loss= 2.9391, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 60700, Minibatch Loss= 2.9386, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 60800, Minibatch Loss= 2.9382, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 60900, Minibatch Loss= 2.9379, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 61000, Minibatch Loss= 2.9375, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 61100, Minibatch Loss= 2.9370, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 61200, Minibatch Loss= 2.9366, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 61300, Minibatch Loss= 2.9363, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 61400, Minibatch Loss= 2.9357, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 61500, Minibatch Loss= 2.9354, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 61600, Minibatch Loss= 2.9348, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 61700, Minibatch Loss= 2.9345, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 61800, Minibatch Loss= 2.9342, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 61900, Minibatch Loss= 2.9337, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 62000, Minibatch Loss= 2.9327, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 62100, Minibatch Loss= 2.9328, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 62200, Minibatch Loss= 2.9325, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 62300, Minibatch Loss= 2.9321, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 62400, Minibatch Loss= 2.9317, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 62500, Minibatch Loss= 2.9314, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 62600, Minibatch Loss= 2.9311, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 62700, Minibatch Loss= 2.9304, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 62800, Minibatch Loss= 2.9302, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 62900, Minibatch Loss= 2.9299, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 63000, Minibatch Loss= 2.9294, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 63100, Minibatch Loss= 2.9291, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 63200, Minibatch Loss= 2.9286, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 63300, Minibatch Loss= 2.9281, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 63400, Minibatch Loss= 2.9278, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 63500, Minibatch Loss= 2.9276, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 63600, Minibatch Loss= 2.9273, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 63700, Minibatch Loss= 2.9267, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 63800, Minibatch Loss= 2.9263, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 63900, Minibatch Loss= 2.9255, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 64000, Minibatch Loss= 2.9254, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 64100, Minibatch Loss= 2.9251, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 64200, Minibatch Loss= 2.9248, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 64300, Minibatch Loss= 2.9244, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 64400, Minibatch Loss= 2.9238, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 64500, Minibatch Loss= 2.9237, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 64600, Minibatch Loss= 2.9232, Training Accuracy= 0.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 64700, Minibatch Loss= 2.9226, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 64800, Minibatch Loss= 2.9219, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 64900, Minibatch Loss= 2.9219, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 65000, Minibatch Loss= 2.9216, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 65100, Minibatch Loss= 2.9212, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 65200, Minibatch Loss= 2.9208, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 65300, Minibatch Loss= 2.9205, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 65400, Minibatch Loss= 2.9201, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 65500, Minibatch Loss= 2.9198, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 65600, Minibatch Loss= 2.9193, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 65700, Minibatch Loss= 2.9190, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 65800, Minibatch Loss= 2.9184, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 65900, Minibatch Loss= 2.9182, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 66000, Minibatch Loss= 2.9177, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 66100, Minibatch Loss= 2.9173, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 66200, Minibatch Loss= 2.9168, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 66300, Minibatch Loss= 2.9159, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 66400, Minibatch Loss= 2.9153, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 66500, Minibatch Loss= 2.9147, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 66600, Minibatch Loss= 2.9139, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 66700, Minibatch Loss= 2.9134, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 66800, Minibatch Loss= 2.9125, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 66900, Minibatch Loss= 2.9118, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 67000, Minibatch Loss= 2.9114, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 67100, Minibatch Loss= 2.9106, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 67200, Minibatch Loss= 2.9100, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 67300, Minibatch Loss= 2.9092, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 67400, Minibatch Loss= 2.9087, Training Accuracy= 0.172\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 67500, Minibatch Loss= 2.9078, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 67600, Minibatch Loss= 2.9074, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 67700, Minibatch Loss= 2.9068, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 67800, Minibatch Loss= 2.9062, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 67900, Minibatch Loss= 2.9056, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 68000, Minibatch Loss= 2.9052, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 68100, Minibatch Loss= 2.9047, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 68200, Minibatch Loss= 2.9040, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 68300, Minibatch Loss= 2.9036, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 68400, Minibatch Loss= 2.9030, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 68500, Minibatch Loss= 2.9027, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 68600, Minibatch Loss= 2.9018, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 68700, Minibatch Loss= 2.9012, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 68800, Minibatch Loss= 2.9009, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 68900, Minibatch Loss= 2.9003, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 69000, Minibatch Loss= 2.9001, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 69100, Minibatch Loss= 2.8994, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 69200, Minibatch Loss= 2.8986, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 69300, Minibatch Loss= 2.8977, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 69400, Minibatch Loss= 2.8971, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 69500, Minibatch Loss= 2.8956, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 69600, Minibatch Loss= 2.8956, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 69700, Minibatch Loss= 2.8950, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 69800, Minibatch Loss= 2.8935, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 69900, Minibatch Loss= 2.8928, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 70000, Minibatch Loss= 2.8924, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 70100, Minibatch Loss= 2.8915, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 70200, Minibatch Loss= 2.8909, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 70300, Minibatch Loss= 2.8899, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 70400, Minibatch Loss= 2.8895, Training Accuracy= 0.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 70500, Minibatch Loss= 2.8895, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 70600, Minibatch Loss= 2.8885, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 70700, Minibatch Loss= 2.8879, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 70800, Minibatch Loss= 2.8872, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 70900, Minibatch Loss= 2.8862, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 71000, Minibatch Loss= 2.8859, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 71100, Minibatch Loss= 2.8852, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 71200, Minibatch Loss= 2.8847, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 71300, Minibatch Loss= 2.8836, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 71400, Minibatch Loss= 2.8834, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 71500, Minibatch Loss= 2.8821, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 71600, Minibatch Loss= 2.8821, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 71700, Minibatch Loss= 2.8805, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 71800, Minibatch Loss= 2.8809, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 71900, Minibatch Loss= 2.8800, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 72000, Minibatch Loss= 2.8794, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 72100, Minibatch Loss= 2.8790, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 72200, Minibatch Loss= 2.8775, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 72300, Minibatch Loss= 2.8773, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 72400, Minibatch Loss= 2.8766, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 72500, Minibatch Loss= 2.8764, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 72600, Minibatch Loss= 2.8755, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 72700, Minibatch Loss= 2.8752, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 72800, Minibatch Loss= 2.8746, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 72900, Minibatch Loss= 2.8735, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 73000, Minibatch Loss= 2.8734, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 73100, Minibatch Loss= 2.8727, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 73200, Minibatch Loss= 2.8721, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 73300, Minibatch Loss= 2.8714, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 73400, Minibatch Loss= 2.8703, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 73500, Minibatch Loss= 2.8698, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 73600, Minibatch Loss= 2.8699, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 73700, Minibatch Loss= 2.8682, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 73800, Minibatch Loss= 2.8684, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 73900, Minibatch Loss= 2.8677, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 74000, Minibatch Loss= 2.8673, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 74100, Minibatch Loss= 2.8663, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 74200, Minibatch Loss= 2.8656, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 74300, Minibatch Loss= 2.8653, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 74400, Minibatch Loss= 2.8645, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 74500, Minibatch Loss= 2.8640, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 74600, Minibatch Loss= 2.8637, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 74700, Minibatch Loss= 2.8628, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 74800, Minibatch Loss= 2.8624, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 74900, Minibatch Loss= 2.8618, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 75000, Minibatch Loss= 2.8605, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 75100, Minibatch Loss= 2.8600, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 75200, Minibatch Loss= 2.8594, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 75300, Minibatch Loss= 2.8592, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 75400, Minibatch Loss= 2.8589, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 75500, Minibatch Loss= 2.8593, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 75600, Minibatch Loss= 2.8588, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 75700, Minibatch Loss= 2.8579, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 75800, Minibatch Loss= 2.8580, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 75900, Minibatch Loss= 2.8571, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 76000, Minibatch Loss= 2.8570, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 76100, Minibatch Loss= 2.8567, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 76200, Minibatch Loss= 2.8562, Training Accuracy= 0.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 76300, Minibatch Loss= 2.8553, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 76400, Minibatch Loss= 2.8553, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 76500, Minibatch Loss= 2.8546, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 76600, Minibatch Loss= 2.8545, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 76700, Minibatch Loss= 2.8536, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 76800, Minibatch Loss= 2.8534, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 76900, Minibatch Loss= 2.8523, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 77000, Minibatch Loss= 2.8526, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 77100, Minibatch Loss= 2.8518, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 77200, Minibatch Loss= 2.8514, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 77300, Minibatch Loss= 2.8508, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 77400, Minibatch Loss= 2.8503, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 77500, Minibatch Loss= 2.8500, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 77600, Minibatch Loss= 2.8494, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 77700, Minibatch Loss= 2.8491, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 77800, Minibatch Loss= 2.8488, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 77900, Minibatch Loss= 2.8480, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 78000, Minibatch Loss= 2.8477, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 78100, Minibatch Loss= 2.8472, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 78200, Minibatch Loss= 2.8461, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 78300, Minibatch Loss= 2.8460, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 78400, Minibatch Loss= 2.8455, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 78500, Minibatch Loss= 2.8447, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 78600, Minibatch Loss= 2.8448, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 78700, Minibatch Loss= 2.8438, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 78800, Minibatch Loss= 2.8431, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 78900, Minibatch Loss= 2.8431, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 79000, Minibatch Loss= 2.8422, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 79100, Minibatch Loss= 2.8422, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 79200, Minibatch Loss= 2.8419, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 79300, Minibatch Loss= 2.8412, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 79400, Minibatch Loss= 2.8410, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 79500, Minibatch Loss= 2.8406, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 79600, Minibatch Loss= 2.8395, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 79700, Minibatch Loss= 2.8387, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 79800, Minibatch Loss= 2.8389, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 79900, Minibatch Loss= 2.8384, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 80000, Minibatch Loss= 2.8381, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 80100, Minibatch Loss= 2.8372, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 80200, Minibatch Loss= 2.8367, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 80300, Minibatch Loss= 2.8364, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 80400, Minibatch Loss= 2.8362, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 80500, Minibatch Loss= 2.8357, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 80600, Minibatch Loss= 2.8351, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 80700, Minibatch Loss= 2.8349, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 80800, Minibatch Loss= 2.8347, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 80900, Minibatch Loss= 2.8337, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 81000, Minibatch Loss= 2.8333, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 81100, Minibatch Loss= 2.8331, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 81200, Minibatch Loss= 2.8322, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 81300, Minibatch Loss= 2.8318, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 81400, Minibatch Loss= 2.8307, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 81500, Minibatch Loss= 2.8312, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 81600, Minibatch Loss= 2.8307, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 81700, Minibatch Loss= 2.8298, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 81800, Minibatch Loss= 2.8297, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 81900, Minibatch Loss= 2.8296, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 82000, Minibatch Loss= 2.8292, Training Accuracy= 0.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 82100, Minibatch Loss= 2.8287, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 82200, Minibatch Loss= 2.8279, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 82300, Minibatch Loss= 2.8273, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 82400, Minibatch Loss= 2.8269, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 82500, Minibatch Loss= 2.8269, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 82600, Minibatch Loss= 2.8266, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 82700, Minibatch Loss= 2.8262, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 82800, Minibatch Loss= 2.8258, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 82900, Minibatch Loss= 2.8251, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 83000, Minibatch Loss= 2.8247, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 83100, Minibatch Loss= 2.8240, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 83200, Minibatch Loss= 2.8241, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 83300, Minibatch Loss= 2.8235, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 83400, Minibatch Loss= 2.8231, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 83500, Minibatch Loss= 2.8228, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 83600, Minibatch Loss= 2.8222, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 83700, Minibatch Loss= 2.8219, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 83800, Minibatch Loss= 2.8214, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 83900, Minibatch Loss= 2.8212, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 84000, Minibatch Loss= 2.8207, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 84100, Minibatch Loss= 2.8200, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 84200, Minibatch Loss= 2.8195, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 84300, Minibatch Loss= 2.8193, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 84400, Minibatch Loss= 2.8188, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 84500, Minibatch Loss= 2.8188, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 84600, Minibatch Loss= 2.8179, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 84700, Minibatch Loss= 2.8179, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 84800, Minibatch Loss= 2.8172, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 84900, Minibatch Loss= 2.8168, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 85000, Minibatch Loss= 2.8165, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 85100, Minibatch Loss= 2.8157, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 85200, Minibatch Loss= 2.8160, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 85300, Minibatch Loss= 2.8151, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 85400, Minibatch Loss= 2.8153, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 85500, Minibatch Loss= 2.8145, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 85600, Minibatch Loss= 2.8141, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 85700, Minibatch Loss= 2.8141, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 85800, Minibatch Loss= 2.8131, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 85900, Minibatch Loss= 2.8135, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 86000, Minibatch Loss= 2.8130, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 86100, Minibatch Loss= 2.8126, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 86200, Minibatch Loss= 2.8125, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 86300, Minibatch Loss= 2.8117, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 86400, Minibatch Loss= 2.8114, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 86500, Minibatch Loss= 2.8109, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 86600, Minibatch Loss= 2.8104, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 86700, Minibatch Loss= 2.8097, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 86800, Minibatch Loss= 2.8097, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 86900, Minibatch Loss= 2.8091, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 87000, Minibatch Loss= 2.8085, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 87100, Minibatch Loss= 2.8084, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 87200, Minibatch Loss= 2.8082, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 87300, Minibatch Loss= 2.8083, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 87400, Minibatch Loss= 2.8075, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 87500, Minibatch Loss= 2.8073, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 87600, Minibatch Loss= 2.8072, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 87700, Minibatch Loss= 2.8064, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 87800, Minibatch Loss= 2.8064, Training Accuracy= 0.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 87900, Minibatch Loss= 2.8057, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 88000, Minibatch Loss= 2.8057, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 88100, Minibatch Loss= 2.8050, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 88200, Minibatch Loss= 2.8049, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 88300, Minibatch Loss= 2.8045, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 88400, Minibatch Loss= 2.8042, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 88500, Minibatch Loss= 2.8039, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 88600, Minibatch Loss= 2.8034, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 88700, Minibatch Loss= 2.8030, Training Accuracy= 0.156\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 88800, Minibatch Loss= 2.8025, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 88900, Minibatch Loss= 2.8023, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 89000, Minibatch Loss= 2.8024, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 89100, Minibatch Loss= 2.8018, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 89200, Minibatch Loss= 2.8015, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 89300, Minibatch Loss= 2.8011, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 89400, Minibatch Loss= 2.8008, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 89500, Minibatch Loss= 2.8003, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 89600, Minibatch Loss= 2.8004, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 89700, Minibatch Loss= 2.7998, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 89800, Minibatch Loss= 2.7994, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 89900, Minibatch Loss= 2.7993, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 90000, Minibatch Loss= 2.7988, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 90100, Minibatch Loss= 2.7988, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 90200, Minibatch Loss= 2.7981, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 90300, Minibatch Loss= 2.7978, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 90400, Minibatch Loss= 2.7974, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 90500, Minibatch Loss= 2.7968, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 90600, Minibatch Loss= 2.7971, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 90700, Minibatch Loss= 2.7968, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 90800, Minibatch Loss= 2.7965, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 90900, Minibatch Loss= 2.7960, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 91000, Minibatch Loss= 2.7954, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 91100, Minibatch Loss= 2.7955, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 91200, Minibatch Loss= 2.7953, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 91300, Minibatch Loss= 2.7950, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 91400, Minibatch Loss= 2.7947, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 91500, Minibatch Loss= 2.7941, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 91600, Minibatch Loss= 2.7940, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 91700, Minibatch Loss= 2.7937, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 91800, Minibatch Loss= 2.7932, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 91900, Minibatch Loss= 2.7932, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 92000, Minibatch Loss= 2.7930, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 92100, Minibatch Loss= 2.7927, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 92200, Minibatch Loss= 2.7922, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 92300, Minibatch Loss= 2.7919, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 92400, Minibatch Loss= 2.7917, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 92500, Minibatch Loss= 2.7916, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 92600, Minibatch Loss= 2.7913, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 92700, Minibatch Loss= 2.7909, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 92800, Minibatch Loss= 2.7903, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 92900, Minibatch Loss= 2.7902, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 93000, Minibatch Loss= 2.7896, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 93100, Minibatch Loss= 2.7899, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 93200, Minibatch Loss= 2.7896, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 93300, Minibatch Loss= 2.7892, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 93400, Minibatch Loss= 2.7891, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 93500, Minibatch Loss= 2.7887, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 93600, Minibatch Loss= 2.7881, Training Accuracy= 0.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 93700, Minibatch Loss= 2.7880, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 93800, Minibatch Loss= 2.7878, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 93900, Minibatch Loss= 2.7878, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 94000, Minibatch Loss= 2.7874, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 94100, Minibatch Loss= 2.7869, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 94200, Minibatch Loss= 2.7868, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 94300, Minibatch Loss= 2.7867, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 94400, Minibatch Loss= 2.7865, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 94500, Minibatch Loss= 2.7861, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 94600, Minibatch Loss= 2.7857, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 6, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 94700, Minibatch Loss= 2.7854, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 94800, Minibatch Loss= 2.7854, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 94900, Minibatch Loss= 2.7851, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 95000, Minibatch Loss= 2.7850, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 95100, Minibatch Loss= 2.7846, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 95200, Minibatch Loss= 2.7840, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 95300, Minibatch Loss= 2.7841, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 95400, Minibatch Loss= 2.7839, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 95500, Minibatch Loss= 2.7831, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 95600, Minibatch Loss= 2.7834, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 95700, Minibatch Loss= 2.7830, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 95800, Minibatch Loss= 2.7830, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 95900, Minibatch Loss= 2.7827, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 96000, Minibatch Loss= 2.7825, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 96100, Minibatch Loss= 2.7822, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 96200, Minibatch Loss= 2.7818, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 96300, Minibatch Loss= 2.7816, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 96400, Minibatch Loss= 2.7810, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 96500, Minibatch Loss= 2.7812, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 96600, Minibatch Loss= 2.7810, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 96700, Minibatch Loss= 2.7807, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 96800, Minibatch Loss= 2.7805, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 96900, Minibatch Loss= 2.7805, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 97000, Minibatch Loss= 2.7799, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 97100, Minibatch Loss= 2.7797, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 97200, Minibatch Loss= 2.7799, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 97300, Minibatch Loss= 2.7795, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 97400, Minibatch Loss= 2.7792, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 97500, Minibatch Loss= 2.7790, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 97600, Minibatch Loss= 2.7784, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 97700, Minibatch Loss= 2.7786, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 97800, Minibatch Loss= 2.7784, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 97900, Minibatch Loss= 2.7782, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 98000, Minibatch Loss= 2.7778, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 98100, Minibatch Loss= 2.7777, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 98200, Minibatch Loss= 2.7776, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 98300, Minibatch Loss= 2.7772, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 98400, Minibatch Loss= 2.7770, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 98500, Minibatch Loss= 2.7769, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 98600, Minibatch Loss= 2.7767, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 98700, Minibatch Loss= 2.7765, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 98800, Minibatch Loss= 2.7762, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 98900, Minibatch Loss= 2.7758, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 99000, Minibatch Loss= 2.7760, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 99100, Minibatch Loss= 2.7757, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 99200, Minibatch Loss= 2.7755, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 99300, Minibatch Loss= 2.7753, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 99400, Minibatch Loss= 2.7750, Training Accuracy= 0.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 99500, Minibatch Loss= 2.7748, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 99600, Minibatch Loss= 2.7746, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 99700, Minibatch Loss= 2.7744, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 99800, Minibatch Loss= 2.7741, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 99900, Minibatch Loss= 2.7732, Training Accuracy= 0.141\n",
      "pred:  [22, 31, 4, 4, 31, 31, 31, 30]\n",
      "act: [3, 17, 28, 8, 19, 8, 11, 3]\n",
      "snr:  10\n",
      "Iter 100000, Minibatch Loss= 2.7739, Training Accuracy= 0.141\n",
      "Training Finished\n",
      "Testing Accuracy Neural: 0.03125\n",
      "Testing Accuracy Kay: 0.625\n"
     ]
    }
   ],
   "source": [
    "#cnn one hot\n",
    "\n",
    "nn_accs = []\n",
    "mle_accs = []\n",
    "\n",
    "snrs = [0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for SNRdB in snrs:\n",
    "\n",
    "    N = 32\n",
    "    SNRdB = 10\n",
    "    m = 32\n",
    "\n",
    "    # Parameters\n",
    "    learning_rate = 0.0001\n",
    "    num_iter = 100000\n",
    "    batch_size = 64\n",
    "\n",
    "    # Network Parameters\n",
    "    num_classes = N\n",
    "\n",
    "    # tf Graph input\n",
    "    X = tf.placeholder(\"float\", [None, m, 2])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "    # Store layers weight & bias\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.random_normal([2, 2, 8])), # filtersize, in channels, outchannels\n",
    "        'out': tf.Variable(tf.random_normal([27*8, num_classes])),\n",
    "        'h2': tf.Variable(tf.random_normal([3, 8, 8])),\n",
    "        'h3': tf.Variable(tf.random_normal([3, 8, 8]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([8])),\n",
    "        'out': tf.Variable(tf.random_normal([num_classes])),\n",
    "        'b2': tf.Variable(tf.random_normal([8])),\n",
    "        'b3': tf.Variable(tf.random_normal([8]))\n",
    "    }\n",
    "\n",
    "    indices = np.sort(np.random.choice(range(N), size=m, replace=False))\n",
    "\n",
    "    test_signals, test_freqs = make_batch_noisy(batch_size, SNRdB, N, m)\n",
    "    test_signals_pair = np.zeros((batch_size, m, 2))\n",
    "    test_signals_pair[:, :, 0] = np.real(test_signals)\n",
    "    test_signals_pair[:, :, 1] = np.imag(test_signals)\n",
    "    \n",
    "    \n",
    "    dict = {}\n",
    "    for i in range(10):\n",
    "        batch_x, batch_y = make_batch_noisy(batch_size, SNRdB, N, m)\n",
    "        batch_x_pair = np.zeros((batch_size, m, 2))\n",
    "        batch_x_pair[:, :, 0] = np.real(test_signals)\n",
    "        batch_x_pair[:, :, 1] = np.imag(test_signals)\n",
    "        dict[i] = (batch_x_pair, batch_y)\n",
    "\n",
    "    def neural_net(x):\n",
    "        layer_1 = tf.add(tf.nn.conv1d(x, weights['h1'], 1, 'VALID'), biases['b1'])\n",
    "        hidden_1 = tf.nn.relu(layer_1)\n",
    "        layer_2 = tf.add(tf.nn.conv1d(hidden_1, weights['h2'], 1, 'VALID'), biases['b2'])\n",
    "        hidden_2 = tf.nn.relu(layer_2)\n",
    "        layer_3 = tf.add(tf.nn.conv1d(hidden_2, weights['h3'], 1, 'VALID'), biases['b3'])\n",
    "        hidden_3 = tf.nn.relu(layer_3)\n",
    "        hidden_3 = tf.reshape(hidden_3, [batch_size, -1])\n",
    "        out_layer = tf.matmul(hidden_3, weights['out']) + biases['out']\n",
    "        return out_layer\n",
    "\n",
    "    # Construct model\n",
    "    logits = neural_net(X)\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    losses, accuracies = [], []\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=Y))  \n",
    "    ''' + 0.01*tf.nn.l2_loss(weights['h1']) + 0.01*tf.nn.l2_loss(weights['h2']) + 0.01*tf.nn.l2_loss(weights['out'])\\\n",
    "    + 0.01*tf.nn.l2_loss(biases['b1']) + 0.01*tf.nn.l2_loss(biases['b2']) + 0.01*tf.nn.l2_loss(biases['out'])'''\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "    # Evaluate model\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Initialize the variables (i.e. assign their default value)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start training\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "\n",
    "        for step in range(1, num_iter + 1):\n",
    "            '''batch_x, batch_y = make_batch_noisy(batch_size, SNRdB, N, m)\n",
    "            batch_x_pair = np.zeros((batch_size, m, 2))\n",
    "            batch_x_pair[:, :, 0] = np.real(test_signals)\n",
    "            batch_x_pair[:, :, 1] = np.imag(test_signals)'''\n",
    "            batch_x_pair, batch_y = dict[step % 10]\n",
    "\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(train_op, feed_dict={X: batch_x_pair, Y: batch_y})\n",
    "            if step % 100 == 0:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc, pred = sess.run([loss_op, accuracy, prediction], feed_dict={X: batch_x_pair,\n",
    "                                                                     Y: batch_y})\n",
    "\n",
    "                print(\"pred: \", [np.argmax(a) for a in pred[:8]])\n",
    "                print(\"act:\", [np.argmax(a) for a in batch_y[:8]])\n",
    "                accuracies.append(acc)\n",
    "                losses.append(loss)\n",
    "                print(\"snr: \", SNRdB)\n",
    "                print(\"Iter \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Training Finished\")\n",
    "\n",
    "        nn_acc = sess.run(accuracy, feed_dict={X: test_signals_pair, Y: test_freqs})\n",
    "        kay_acc = test_kays(test_signals, test_freqs, N)\n",
    "        \n",
    "        print(\"Testing Accuracy Neural:\", nn_acc)\n",
    "\n",
    "        print(\"Testing Accuracy Kay:\", mle_acc)\n",
    "        nn_accs.append(nn_acc)\n",
    "        mle_accs.append(mle_acc)\n",
    "#np.save('./data/snrs', snrs)\n",
    "#np.save('./data/nn_accs2', nn_accs)\n",
    "#np.save('./data/mle_accs2', mle_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  [356, 316, 184, 356, 194, 356, 276, 356]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 999, Minibatch Loss= 58.2588, Training Accuracy= 0.172\n",
      "pred:  [219, 443, 174, 443, 443, 356, 443, 328]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 1998, Minibatch Loss= 27.6268, Training Accuracy= 0.422\n",
      "pred:  [102, 384, 495, 324, 115, 356, 295, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 2997, Minibatch Loss= 10.7710, Training Accuracy= 0.672\n",
      "pred:  [509, 384, 495, 436, 115, 356, 337, 184]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 3996, Minibatch Loss= 4.2767, Training Accuracy= 0.719\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 4995, Minibatch Loss= 2.3898, Training Accuracy= 0.750\n",
      "pred:  [509, 161, 5, 455, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 5994, Minibatch Loss= 1.6593, Training Accuracy= 0.891\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 6993, Minibatch Loss= 1.4383, Training Accuracy= 0.906\n",
      "pred:  [509, 384, 495, 456, 115, 356, 441, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 7992, Minibatch Loss= 1.3073, Training Accuracy= 0.969\n",
      "pred:  [509, 202, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 8991, Minibatch Loss= 1.4996, Training Accuracy= 0.844\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 9990, Minibatch Loss= 1.2330, Training Accuracy= 0.938\n",
      "pred:  [509, 337, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 10989, Minibatch Loss= 1.3218, Training Accuracy= 0.938\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 11988, Minibatch Loss= 1.3111, Training Accuracy= 0.906\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 12987, Minibatch Loss= 1.2813, Training Accuracy= 0.891\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 13986, Minibatch Loss= 1.2224, Training Accuracy= 0.922\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 14985, Minibatch Loss= 1.2252, Training Accuracy= 0.969\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 51]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 15984, Minibatch Loss= 1.3336, Training Accuracy= 0.891\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 16983, Minibatch Loss= 1.2620, Training Accuracy= 0.922\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 17982, Minibatch Loss= 1.3325, Training Accuracy= 0.922\n",
      "pred:  [509, 180, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 18981, Minibatch Loss= 1.2848, Training Accuracy= 0.891\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 19980, Minibatch Loss= 1.1943, Training Accuracy= 0.953\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 20979, Minibatch Loss= 1.0961, Training Accuracy= 0.984\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 21978, Minibatch Loss= 1.2393, Training Accuracy= 0.969\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 22977, Minibatch Loss= 1.1837, Training Accuracy= 0.984\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 23976, Minibatch Loss= 1.1922, Training Accuracy= 0.938\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 24975, Minibatch Loss= 1.2469, Training Accuracy= 0.984\n",
      "pred:  [47, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 25974, Minibatch Loss= 1.3800, Training Accuracy= 0.938\n",
      "pred:  [509, 384, 498, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 26973, Minibatch Loss= 1.2038, Training Accuracy= 0.922\n",
      "pred:  [509, 384, 495, 251, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 27972, Minibatch Loss= 1.2725, Training Accuracy= 0.938\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 28971, Minibatch Loss= 1.3078, Training Accuracy= 0.906\n",
      "pred:  [509, 384, 495, 456, 115, 356, 337, 51]\n",
      "act: [509, 384, 495, 456, 115, 356, 337, 56]\n",
      "snr:  10\n",
      "Iter 29970, Minibatch Loss= 1.2626, Training Accuracy= 0.938\n",
      "Training Finished\n",
      "Testing Accuracy Neural: 0.078125\n",
      "Testing Accuracy Kay: 0.75\n"
     ]
    }
   ],
   "source": [
    "#non linear one hot\n",
    "\n",
    "nn_accs = []\n",
    "mle_accs = []\n",
    "\n",
    "snrs = [0]\n",
    "\n",
    "for SNRdB in snrs:\n",
    "\n",
    "    N = 512\n",
    "    SNRdB = 10\n",
    "    m = 32\n",
    "\n",
    "    # Parameters\n",
    "    learning_rate = 0.005\n",
    "    num_iter = 30000\n",
    "    batch_size = 64\n",
    "\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = 64\n",
    "    n_hidden_2 = 64 \n",
    "    n_hidden_3 = 512\n",
    "    num_input = m * 2 \n",
    "    num_classes = N\n",
    "\n",
    "    # tf Graph input\n",
    "    X = tf.placeholder(\"float\", [None, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "    # Store layers weight & bias\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_1, num_classes])),\n",
    "        'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]))\n",
    "        #'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "        'out': tf.Variable(tf.random_normal([num_classes])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden_2]))\n",
    "        #'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    }\n",
    "\n",
    "    indices = np.sort(np.random.choice(range(N), size=m, replace=False))\n",
    "    \n",
    "    test_signals, test_freqs = make_batch_noisy(batch_size, SNRdB, N, m)\n",
    "    test_signals_pair = [imag_to_pair(x) for x in test_signals]\n",
    "    \n",
    "    dict = {}\n",
    "    training_samples = 500\n",
    "    for i in range(training_samples):\n",
    "        batch_x, batch_y = make_batch_noisy(batch_size, SNRdB, N, m)\n",
    "        batch_x_pair = [imag_to_pair(x) for x in batch_x]\n",
    "        dict[i] = (batch_x_pair, batch_y)\n",
    "\n",
    "    def neural_net(x):\n",
    "        layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "        hidden_1 = tf.nn.relu(layer_1)\n",
    "        hidden_1 = tf.nn.dropout(hidden_1, 0.5)\n",
    "        layer_2 = tf.add(tf.matmul(hidden_1, weights['h2']), biases['b2'])\n",
    "        hidden_2 = tf.nn.relu(layer_2)\n",
    "        hidden_2 = tf.nn.dropout(hidden_2, 0.5)\n",
    "        #layer_3 = tf.add(tf.matmul(hidden_2, weights['h3']), biases['b3'])\n",
    "        #hidden_3 = tf.nn.relu(layer_3)\n",
    "\n",
    "        out_layer = tf.matmul(hidden_2, weights['out']) + biases['out']\n",
    "        return out_layer\n",
    "\n",
    "    # Construct model\n",
    "    logits = neural_net(X)\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    losses, accuracies = [], []\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=Y)) + 0.01*tf.nn.l2_loss(weights['h1']) + 0.01*tf.nn.l2_loss(weights['h2']) + 0.01*tf.nn.l2_loss(weights['out'])\\\n",
    "    + 0.01*tf.nn.l2_loss(biases['b1']) + 0.01*tf.nn.l2_loss(biases['b2']) + 0.01*tf.nn.l2_loss(biases['out'])\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "    # Evaluate model\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Initialize the variables (i.e. assign their default value)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start training\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "\n",
    "        for step in range(1, num_iter + 1):\n",
    "            #batch_x, batch_y = make_batch_noisy(batch_size, SNRdB, N, m)\n",
    "            #batch_x = [imag_to_pair(x) for x in batch_x]\n",
    "            batch_x, batch_y = dict[i % training_samples]\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            if step % 999 == 0:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc, pred = sess.run([loss_op, accuracy, prediction], feed_dict={X: batch_x,\n",
    "                                                                     Y: batch_y})\n",
    "                print(\"pred: \", [np.argmax(a) for a in pred[:8]])\n",
    "                print(\"act:\", [np.argmax(a) for a in batch_y[:8]])\n",
    "                accuracies.append(acc)\n",
    "                losses.append(loss)\n",
    "                print(\"snr: \", SNRdB)\n",
    "                print(\"Iter \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Training Finished\")\n",
    "\n",
    "        nn_acc = sess.run(accuracy, feed_dict={X: test_signals_pair, Y: test_freqs})\n",
    "        kay_acc = test_kays(test_signals, test_freqs, N)\n",
    "        \n",
    "        print(\"Testing Accuracy Neural:\", nn_acc)\n",
    "\n",
    "        print(\"Testing Accuracy Kay:\", kay_acc)\n",
    "        nn_accs.append(nn_acc)\n",
    "        mle_accs.append(kay_acc)\n",
    "#np.save('./data/snrs', snrs)\n",
    "#np.save('./data/nn_accs2', nn_accs)\n",
    "#np.save('./data/mle_accs2', mle_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nonlinear regression\n",
    "\n",
    "nn_accs = []\n",
    "mle_accs = []\n",
    "\n",
    "snrs = [0]\n",
    "\n",
    "for SNRdB in snrs:\n",
    "\n",
    "    N = 512\n",
    "    #SNRdB = 0\n",
    "    m = 512\n",
    "\n",
    "    # Parameters\n",
    "    learning_rate = 0.05\n",
    "    num_iter = 2500\n",
    "    batch_size = 64\n",
    "\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = 32#128\n",
    "    n_hidden_2 = 32#64 \n",
    "    n_hidden_3 = 32#128\n",
    "    n_hidden_4 = 32#128\n",
    "    n_hidden_5 = 32#128\n",
    "    num_input = m * 2 #512 \n",
    "    num_classes = N\n",
    "\n",
    "    # tf Graph input\n",
    "    X = tf.placeholder(\"float\", [None, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, 1])\n",
    "\n",
    "    # Store layers weight & bias\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_3, 1])),\n",
    "        'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "        'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "        'h4': tf.Variable(tf.random_normal([n_hidden_3, n_hidden_4])),\n",
    "        'h5': tf.Variable(tf.random_normal([n_hidden_4, n_hidden_5]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "        'out': tf.Variable(tf.random_normal([1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "        'b4': tf.Variable(tf.random_normal([n_hidden_4])),\n",
    "        'b5': tf.Variable(tf.random_normal([n_hidden_5])),\n",
    "    }\n",
    "\n",
    "    indices = np.sort(np.random.choice(range(N), size=m, replace=False))\n",
    "\n",
    "    test_signals, test_freqs, test_indices = batch_noisy_subsampled_raw(N, SNRdB, m, batch_size, indices)\n",
    "\n",
    "    def neural_net(x):\n",
    "        layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "        hidden_1 = tf.nn.relu(layer_1)\n",
    "        hidden_1 = tf.nn.dropout(hidden_1, 0.5)\n",
    "        layer_2 = tf.add(tf.matmul(hidden_1, weights['h2']), biases['b2'])\n",
    "        hidden_2 = tf.nn.relu(layer_2)\n",
    "        hidden_2 = tf.nn.dropout(hidden_2, 0.5)\n",
    "        layer_3 = tf.add(tf.matmul(hidden_2, weights['h3']), biases['b3'])\n",
    "        hidden_3 = tf.nn.relu(layer_3)\n",
    "        hidden_3 = tf.nn.dropout(hidden_3, 0.5)\n",
    "        layer_4 = tf.add(tf.matmul(hidden_3, weights['h4']), biases['b4'])\n",
    "        hidden_4 = tf.nn.relu(layer_4)\n",
    "        hidden_4 = tf.nn.dropout(hidden_4, 0.5)\n",
    "        layer_5 = tf.add(tf.matmul(hidden_4, weights['h5']), biases['b5'])\n",
    "        hidden_5 = tf.nn.relu(layer_5)\n",
    "        hidden_5 = tf.nn.dropout(hidden_5, 0.5)\n",
    "\n",
    "        out_layer = tf.matmul(hidden_5, weights['out']) + biases['out']\n",
    "        return out_layer\n",
    "\n",
    "    # Construct model\n",
    "    logits = neural_net(X)\n",
    "    prediction = tf.cast(logits, dtype=tf.int32)\n",
    "    losses, accuracies = [], []\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    #loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    #    logits=logits, labels=Y))\n",
    "    \n",
    "    loss_op = tf.reduce_mean((logits - Y) ** 2)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "    # Evaluate model\n",
    "    correct_pred = tf.equal(prediction, tf.cast(Y, dtype=tf.int32))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Initialize the variables (i.e. assign their default value)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start training\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "\n",
    "        for step in range(1, num_iter + 1):\n",
    "            batch_x, batch_y, batch_ind = batch_noisy_subsampled_raw(N, SNRdB, m, batch_size, indices)\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            if step % 100 == 0:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc, pred = sess.run([loss_op, accuracy, prediction], feed_dict={X: test_signals,\n",
    "                                                                     Y: test_freqs})\n",
    "                #print(\"pred: \", [[i for i in a] for a in pred])\n",
    "                #print(\"act:\", batch_y)\n",
    "                accuracies.append(acc)\n",
    "                losses.append(loss)\n",
    "                print(\"snr: \", SNRdB)\n",
    "                print(\"Iter \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Training Finished\")\n",
    "\n",
    "        nn_acc = sess.run(accuracy, feed_dict={X: test_signals, Y: test_freqs})\n",
    "        mle_acc = test_noisy_subsampled_mle(N, test_signals, test_freqs, test_indices)\n",
    "        \n",
    "        print(\"Testing Accuracy Neural:\", nn_acc)\n",
    "\n",
    "        print(\"Testing Accuracy MLE:\", mle_acc)\n",
    "        nn_accs.append(nn_acc)\n",
    "        mle_accs.append(mle_acc)\n",
    "#np.save('./data/snrs', snrs)\n",
    "#np.save('./data/nn_accs2', nn_accs)\n",
    "#np.save('./data/mle_accs2', mle_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##linear model\n",
    "\n",
    "nn_accs = []\n",
    "mle_accs = []\n",
    "\n",
    "snrs = [0]\n",
    "\n",
    "for SNRdB in snrs:\n",
    "\n",
    "    N = 512\n",
    "    SNRdB = 10\n",
    "    m = 32\n",
    "\n",
    "    # Parameters\n",
    "    learning_rate = 0.01\n",
    "    num_iter = 1000\n",
    "    batch_size = 64\n",
    "\n",
    "    # Network Parameters\n",
    "    n_hidden_1 = 512#128\n",
    "    n_hidden_2 = 512#64 \n",
    "    n_hidden_3 = 512#128\n",
    "    num_input = m * 2 #512 \n",
    "    num_classes = N\n",
    "\n",
    "    # tf Graph input\n",
    "    X = tf.placeholder(\"float\", [None, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "    # Store layers weight & bias\n",
    "    weights = {\n",
    "        'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "        'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "        'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden_3, num_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "        'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "    }\n",
    "\n",
    "    indices = np.sort(np.random.choice(range(N), size=m, replace=False))\n",
    "\n",
    "    test_signals, test_freqs = make_batch_noisy(batch_size, SNRdB, N, m)\n",
    "    test_signals_pair = [imag_to_pair(sig) for sig in test_signals]\n",
    "\n",
    "    def neural_net(x):\n",
    "        layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "        layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "        layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "\n",
    "        out_layer = tf.matmul(layer_3, weights['out']) + biases['out']\n",
    "        return out_layer\n",
    "\n",
    "    # Construct model\n",
    "    logits = neural_net(X)\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    losses, accuracies = [], []\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=Y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "    # Evaluate model\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    # Initialize the variables (i.e. assign their default value)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start training\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "\n",
    "        for step in range(1, num_iter + 1):\n",
    "            batch_x, batch_y = make_batch_noisy(batch_size, SNRdB, N, m)\n",
    "            batch_x = [imag_to_pair(x) for x in batch_x]\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            if step % 10 == 0:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc, pred = sess.run([loss_op, accuracy, prediction], feed_dict={X: batch_x,\n",
    "                                                                     Y: batch_y})\n",
    "                accuracies.append(acc)\n",
    "                losses.append(loss)\n",
    "                print(\"snr: \", SNRdB)\n",
    "                print(\"Iter \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Training Finished\")\n",
    "\n",
    "        nn_acc = sess.run(accuracy, feed_dict={X: test_signals_pair, Y: test_freqs})\n",
    "        kay_acc = test_kays(test_signals, test_freqs, N)\n",
    "        \n",
    "        print(\"Testing Accuracy Neural:\", nn_acc)\n",
    "\n",
    "        print(\"Testing Accuracy Kay:\", mle_acc)\n",
    "        nn_accs.append(nn_acc)\n",
    "        mle_accs.append(mle_acc)\n",
    "#np.save('./data/snrs', snrs)\n",
    "#np.save('./data/nn_accs2', nn_accs)\n",
    "#np.save('./data/mle_accs2', mle_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27239fbc4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.load('./data/snrs.npy'), np.load('./data/nn_accs2.npy'), '-bo')\n",
    "plt.plot(np.load('./data/snrs.npy'), np.load('./data/mle_accs2.npy'), '-ro') \n",
    "plt.show()\n",
    "\n",
    "# testing snr's for N=512, M=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7iIiJUjJXUSkBCm5i4iUoP8P95nlbsFWQ6wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27231652048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.load('./data/ms.npy'), np.load('./data/nn_accs.npy'), '-bo')\n",
    "plt.plot(np.load('./data/ms.npy'), np.load('./data/mle_accs.npy'), '-ro') \n",
    "plt.show()\n",
    "\n",
    "# testing subsampling m's for N=512, snr=0db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmYGwP8HPbS+FUutPpQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d6f7bd3908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEDCAYAAAA/eB+kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf42+IUOGAlXyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d6f8fd3f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n500 iter, N=256,3 hidden layer each w 256 neuron, batchsize=32\\nfully sampled: test accuracy ~98%\\nm=240: test accuracy ~28%'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(accuracies)\n",
    "plt.show()\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "500 iter, N=256,3 hidden layer each w 256 neuron, batchsize=32\n",
    "fully sampled: test accuracy ~98%\n",
    "m=240: test accuracy ~28%'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
