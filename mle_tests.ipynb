{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_signal(w,theta,n):\n",
    "    \"\"\"\n",
    "    Assumes normalized amplitude\n",
    "    \"\"\"\n",
    "    t = np.arange(n)\n",
    "    signal = np.exp(1j*(w*t + theta))\n",
    "    return signal\n",
    "\n",
    "def make_signal_random(w,theta,N,m):\n",
    "    sig = make_signal(w, theta, N)\n",
    "    chosen_indices = np.sort(np.random.choice(range(N), size=m, replace=False))\n",
    "    return (np.take(sig, chosen_indices), chosen_indices)\n",
    "\n",
    "def make_signal_2power(w,theta,N,m):\n",
    "    sig = make_signal(w, theta, N)\n",
    "    chosen_indices = list(set([(j * 2**i) % N for j in range(m) for i in range(int(np.log2(N)))]))\n",
    "    return (np.take(sig, chosen_indices), chosen_indices)\n",
    "\n",
    "def make_noise(sigma2,n):\n",
    "    noise_scaling = np.sqrt(sigma2/2)\n",
    "    # noise is complex valued\n",
    "    noise  = noise_scaling*np.random.randn(n) + 1j*noise_scaling*np.random.randn(n)\n",
    "    return noise\n",
    "    \n",
    "\n",
    "def make_noisy_signal(w,theta,SNRdb,n):\n",
    "    sigma2 = get_sigma2_from_snrdb(SNRdb)\n",
    "    signal = make_signal(w,theta,n)\n",
    "    noise  = make_noise(sigma2,n)\n",
    "    return signal + noise\n",
    "\n",
    "def make_noisy_signal_random(w, theta, SNRdb, N, m):\n",
    "    sigma2 = get_sigma2_from_snrdb(SNRdb)\n",
    "    signal, inds = make_signal_random(w, theta, N, m)\n",
    "    noise = make_noise(sigma2, m)\n",
    "    return signal+noise, inds\n",
    "\n",
    "def make_noisy_signal_2power(w, theta, SNRdb, N, m):\n",
    "    sigma2 = get_sigma2_from_snrdb(SNRdb)\n",
    "    signal, inds = make_signal_2power(w, theta, N, m)\n",
    "    noise = make_noise(sigma2, len(inds))\n",
    "    return signal+noise, inds\n",
    "\n",
    "def make_batch_noisy_random(batch_size, SNRdb, N, m):\n",
    "    signals, freqs, inds = [], [], []\n",
    "    for i in range(batch_size):\n",
    "        freq = np.random.randint(0, N)\n",
    "        w = (2 * np.pi * freq / N) % (2 * np.pi)\n",
    "        sig, ind = make_noisy_signal_random(w, 0, SNRdb, N, m)\n",
    "        signals.append(sig)\n",
    "        freqs.append(freq)\n",
    "        inds.append(ind)\n",
    "    return signals, one_hot(N, batch_size, freqs), inds\n",
    "    \n",
    "def make_batch_noisy_2power(batch_size, SNRdb, N, m):\n",
    "    signals, freqs, inds = [], [], []\n",
    "    for i in range(batch_size):\n",
    "        freq = np.random.randint(0, N)\n",
    "        w = (2 * np.pi * freq / N) % (2 * np.pi)\n",
    "        sig, ind = make_noisy_signal_2power(w, 0, SNRdb, N, m)\n",
    "        signals.append(sig)\n",
    "        freqs.append(freq)\n",
    "        inds.append(ind)\n",
    "    return signals, one_hot(N, batch_size, freqs), inds\n",
    "\n",
    "    \n",
    "# N = divisor of w0\n",
    "# m = num samples\n",
    "def make_batch_noisy(batch_size, SNRdb, N, m, binary=False):\n",
    "    signals, freqs = [], []\n",
    "    for i in range(batch_size):\n",
    "        freq = np.random.randint(0, N)\n",
    "        w = (2 * np.pi * freq / N) % (2 * np.pi)\n",
    "        sig = make_noisy_signal(w, 0, SNRdb, m)\n",
    "        signals.append(sig)\n",
    "        freqs.append(freq)\n",
    "    if binary:\n",
    "        return signals, make_binary(freqs, N), one_hot(N, batch_size, freqs)\n",
    "    return signals, one_hot(N, batch_size, freqs)\n",
    "\n",
    "# N = divisor of w0\n",
    "# m = num samples\n",
    "def make_batch_noisy_lohi(batch_size, SNRdb, N, m):\n",
    "    freqs = []\n",
    "    freqs.append(np.random.randint(0, N))\n",
    "    test_signals, test_freqs = make_noisy_lohi(SNRdB, N, m, freqs[-1])\n",
    "    for i in range(1, batch_size):\n",
    "        freqs.append(np.random.randint(0, N))\n",
    "        a, b = make_noisy_lohi(SNRdB, N, m, freqs[-1])\n",
    "        test_signals.extend(a)\n",
    "        test_freqs.extend(b)\n",
    "    return test_signals, test_freqs, freqs\n",
    "\n",
    "def make_noisy_lohi(SNRdb, N, m, freq):\n",
    "    signals, vals = [], []\n",
    "    steps = int(np.log2(N))\n",
    "    w = (2 * np.pi * freq / N) % (2 * np.pi)\n",
    "    sig = make_noisy_signal(w, 0, SNRdb, m * (2**steps))\n",
    "    for i in range(int(np.log2(N))):\n",
    "        signals.append([sig[a * (2**i)] for a in range(m)])\n",
    "        if (freq * (2**i)) % (N) < N / 2:\n",
    "            vals.append([1, 0])\n",
    "        else:\n",
    "            vals.append([0, 1])\n",
    "    return signals, vals\n",
    "        \n",
    "\n",
    "def make_batch_singleton(batch_size, SNRdb, N, m, default=-1): # 0 = zero, 1 = single, 2 = multi\n",
    "    signals, freqs = [], []\n",
    "    sigma2 = get_sigma2_from_snrdb(SNRdB)\n",
    "    for i in range(batch_size):\n",
    "        val = np.random.poisson(0.79)\n",
    "        if default >= 0:\n",
    "            val = default\n",
    "        if val == 0:\n",
    "            signals.append(make_noise(0, m))\n",
    "            freqs.append([1, 0, 0])\n",
    "        if val == 1:\n",
    "            signals.append(make_noisy_signal(2 * np.pi * np.random.randint(0, N) / N, 0, SNRdB, m))\n",
    "            freqs.append([0, 1, 0])\n",
    "        if val >= 2:\n",
    "            signal = make_signal(2 * np.pi * np.random.randint(0, N) / N, 0, m)\n",
    "            for i in range(val - 1):\n",
    "                signal += make_signal(2 * np.pi * np.random.randint(0, N) / N, 0, m)\n",
    "            signals.append(signal + make_noise(sigma2, m))\n",
    "            freqs.append([0, 0, 1])\n",
    "    return signals, freqs\n",
    "\n",
    "def get_sigma2_from_snrdb(SNR_db):\n",
    "    return 10**(-SNR_db/10)\n",
    "\n",
    "def kay_weights(N):\n",
    "    scaling = (3.0/2)*N/(N**2 - 1)\n",
    "    \n",
    "    w = [1 - ((i - (N/2 - 1))/(N/2))**2 for i in range(N-1)]\n",
    "    \n",
    "    return scaling*np.array(w)\n",
    "\n",
    "def kays_method(my_signal):\n",
    "    N = len(my_signal)\n",
    "    w = kay_weights(N)\n",
    "    \n",
    "    angle_diff = np.angle(np.conj(my_signal[0:-1])*my_signal[1:])\n",
    "    need_to_shift = np.any(angle_diff < -np.pi/2)\n",
    "    if need_to_shift:    \n",
    "        neg_idx = angle_diff < 0\n",
    "        angle_diff[neg_idx] += np.pi*2\n",
    "    \n",
    "    return w.dot(angle_diff)\n",
    "\n",
    "def kays_singleton_accuracy(test_signals, test_freqs, N):\n",
    "    diffs = [s - make_signal(kays_method(s), 0, N) for s in test_signals]\n",
    "    thresh, single_acc, other_acc, best_thresh = 0.0, 0, 0, 0\n",
    "    best = 0\n",
    "    for i in range(150):\n",
    "        vals = [(sum(np.absolute(s)) / N) < thresh for s in diffs]\n",
    "        corr = [1 for i in range(len(test_freqs)) if (test_freqs[i] == [0, 1, 0] and vals[i] == 1) or ((test_freqs[i] != [0, 1, 0] and vals[i] == 0))]\n",
    "        corr = sum(corr)\n",
    "        #single = sum([vals[d] for d in range(len(vals)) if test_freqs[d] == [0, 1, 0]]) / len([vals[d] for d in range(len(vals)) if test_freqs[d] == [0, 1, 0]])\n",
    "        #other = sum([not vals[d] for d in range(len(vals)) if test_freqs[d] != [0, 1, 0]]) / len([vals[d] for d in range(len(vals)) if test_freqs[d] != [0, 1, 0]])        \n",
    "        #if single*2 + other > single_acc*2 + other_acc and single > 0.2 and other > 0.2:\n",
    "        #    single_acc = single\n",
    "        #    other_acc = other\n",
    "        #    best_thresh = thresh\n",
    "        if corr > best:\n",
    "            best = corr\n",
    "            best_thresh = thresh\n",
    "        thresh += 0.05\n",
    "    print('thresh: ', best_thresh)\n",
    "    return best / len(test_signals)\n",
    "\n",
    "def test_kays(signals, freqs, N):\n",
    "    count = 0\n",
    "    for sig, freq in zip(signals, freqs):\n",
    "        res = kays_method(sig)\n",
    "        res = round(res * N / (2 * np.pi))\n",
    "        if np.argmax(freq) == res:\n",
    "            count += 1\n",
    "    return count / len(signals)\n",
    "\n",
    "def test_mle(signals, freqs, N, m):\n",
    "    count = 0\n",
    "    for sig, freq in zip(signals, freqs):\n",
    "        cleans = [make_signal(np.pi * 2 * w / N, 0, m) for w in range(N)]\n",
    "        dots = [np.absolute(np.vdot(sig, clean)) for clean in cleans]\n",
    "        if np.argmax(dots) == np.argmax(freq):\n",
    "            count += 1\n",
    "    return count / len(signals)\n",
    "    \n",
    "def make_binary(freqs, N):\n",
    "    w = math.ceil(np.log2(N))\n",
    "    return [[int(a) for a in list(np.binary_repr(f, width=w))] for f in freqs] \n",
    "\n",
    "def binary_to_int(binary_string):\n",
    "    return tf.reduce_sum(\n",
    "    tf.cast(tf.reverse(tensor=binary_string, axis=[0]), dtype=tf.int64)\n",
    "    * 2 ** tf.range(tf.cast(tf.size(binary_string), dtype=tf.int64)))\n",
    "    '''y = 0\n",
    "    for i,j in enumerate(x):\n",
    "        y += j<<i\n",
    "    return y'''\n",
    "\n",
    "def hamming(pred, act):\n",
    "    return np.count_nonzero(pred != act)\n",
    "\n",
    "def one_hot(N, batch_size, freqs):\n",
    "    freqs_one_hot = np.zeros((batch_size, N))\n",
    "    freqs_one_hot[np.arange(batch_size), freqs] = 1\n",
    "    return freqs_one_hot\n",
    "\n",
    "def test_noisy_mle(N, m, signals, freqs):\n",
    "    count = 0  \n",
    "    cleans = [make_signal(2*np.pi*i/N, 0, m) for i in range(N)]\n",
    "                     \n",
    "    for index in range(len(signals)):\n",
    "        dots = [np.absolute(np.vdot(signals[index], cleans[i])) for i in range(N)]\n",
    "        if np.argmax(freqs[index]) == np.argmax(dots):\n",
    "            count += 1\n",
    "    return count / len(freqs)\n",
    "\n",
    "def test_noisy_mle_random(N, m, signals, freqs, inds):\n",
    "    count = 0  \n",
    "                     \n",
    "    for index in range(len(signals)):\n",
    "        cleans = [np.take(make_signal(2*np.pi*i/N, 0, N), inds[index]) for i in range(N)]\n",
    "        dots = [np.absolute(np.vdot(signals[index], cleans[i])) for i in range(N)]\n",
    "        if np.argmax(freqs[index]) == np.argmax(dots):\n",
    "            count += 1\n",
    "    return count / len(freqs)\n",
    "\n",
    "def bit_to_freq(bits, N):\n",
    "    possible = [i for i in range(N)]\n",
    "    for b in bits:\n",
    "        if b[0]:\n",
    "            possible = possible[:len(possible)//2]\n",
    "        else:\n",
    "            possible = possible[len(possible)//2:]\n",
    "    return possible[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.491\n",
      "0.385\n",
      "0.318\n",
      "0.26\n",
      "0.196\n",
      "0.177\n",
      "0.127\n",
      "0.094\n"
     ]
    }
   ],
   "source": [
    "# test mle detection for singletons - first m samples\n",
    "\n",
    "snrs = [8, 6, 4, 2, 0, -2, -4, -6]\n",
    "N = 27000 \n",
    "m = 300\n",
    "batch_size = 1000\n",
    "\n",
    "res = []\n",
    "\n",
    "for SNRdB in snrs:\n",
    "    test_signals, test_freqs = make_batch_noisy(batch_size, SNRdB, N, m, binary=False)\n",
    "    res.append(test_noisy_mle(N, m, test_signals, test_freqs))\n",
    "    print(res[-1])\n",
    "    \n",
    "    \n",
    "np.save('./data/freq_detect/snrs', snrs)\n",
    "np.save('./data/freq_detect/mle_first', res)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-face19daec72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mSNRdB\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msnrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtest_signals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_freqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_inds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_batch_noisy_random\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSNRdB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_noisy_mle_random\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_signals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_freqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_inds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-feadac61a569>\u001b[0m in \u001b[0;36mtest_noisy_mle_random\u001b[1;34m(N, m, signals, freqs, inds)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[0mcleans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_signal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m         \u001b[0mdots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcleans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdots\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-feadac61a569>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[0mcleans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_signal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m         \u001b[0mdots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcleans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdots\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-feadac61a569>\u001b[0m in \u001b[0;36mmake_signal\u001b[1;34m(w, theta, n)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m      5\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0msignal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1j\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test mle detection for singletons - random m samples\n",
    "\n",
    "snrs = [8, 6, 4, 2, 0, -2, -4, -6]\n",
    "N = 27000 \n",
    "m = 300\n",
    "batch_size = 1000\n",
    "\n",
    "res = []\n",
    "\n",
    "for SNRdB in snrs:\n",
    "    test_signals, test_freqs, test_inds = make_batch_noisy_random(batch_size, SNRdB, N, m)\n",
    "    res.append(test_noisy_mle_random(N, m, test_signals, test_freqs, test_inds))\n",
    "    print(res[-1])\n",
    "    \n",
    "np.save('./data/freq_detect/snrs', snrs)\n",
    "np.save('./data/freq_detect/mle_random', res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test mle detection for singletons - 2 power m samples each (same as divide & conq)\n",
    "\n",
    "snrs = [8, 6, 4, 2, 0, -2, -4, -6]\n",
    "N = 27000 \n",
    "m = 41#300\n",
    "batch_size = 1000\n",
    "\n",
    "res = []\n",
    "\n",
    "for SNRdB in snrs:\n",
    "    test_signals, test_freqs, test_inds = make_batch_noisy_2power(batch_size, SNRdB, N, m)\n",
    "    res.append(test_noisy_mle_random(N, m, test_signals, test_freqs, test_inds))\n",
    "    print(res[-1])\n",
    "    \n",
    "np.save('./data/freq_detect/snrs', snrs)\n",
    "np.save('./data/freq_detect/mle_2power', res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
