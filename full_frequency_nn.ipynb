{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"lines.dashed_pattern\" on line 18 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"lines.dashdot_pattern\" on line 19 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"lines.dotted_pattern\" on line 20 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"lines.scale_dashes\" on line 21 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"patch.force_edgecolor\" on line 33 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"hatch.color\" on line 37 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"hatch.linewidth\" on line 38 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"hist.bins\" on line 40 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"axes.titlepad\" on line 177 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"axes.formatter.offset_threshold\" on line 200 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"axes.autolimit_mode\" on line 213 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.year\" on line 223 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.month\" on line 224 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.day\" on line 225 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.hour\" on line 226 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.minute\" on line 227 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.second\" on line 228 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"date.autoformatter.microsecond\" on line 229 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.top\" on line 234 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.bottom\" on line 235 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.major.top\" on line 246 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.major.bottom\" on line 247 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.minor.top\" on line 248 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"xtick.minor.bottom\" on line 249 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.left\" on line 251 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.right\" on line 252 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.major.left\" on line 263 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.major.right\" on line 264 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.minor.left\" on line 265 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"ytick.minor.right\" on line 266 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"scatter.marker\" on line 338 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\__init__.py:1076: UserWarning: Bad val \"auto\" on line #353\n",
      "\t\"boxplot.flierprops.markerfacecolor: auto\n",
      "\"\n",
      "\tin file \"c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle\"\n",
      "\tKey boxplot.flierprops.markerfacecolor: auto does not look like a color arg\n",
      "  (val, error_details, msg))\n",
      "\n",
      "Bad key \"boxplot.meanprops.marker\" on line 360 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"boxplot.meanprops.markerfacecolor\" on line 361 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"boxplot.meanprops.markeredgecolor\" on line 362 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"boxplot.meanprops.markersize\" on line 363 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key \"_internal.classic_mode\" on line 513 in\n",
      "c:\\users\\jains\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from functools import reduce\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SIGNAL UTILS\n",
    "\n",
    "def get_sigma2_from_snrdb(SNR_db):\n",
    "    return 10**(-SNR_db/10)\n",
    "\n",
    "def make_signal(w, theta, m):\n",
    "    \"\"\"\n",
    "    Assumes normalized amplitude\n",
    "    \"\"\"\n",
    "    t = np.arange(m)\n",
    "    signal = np.exp(1j*(w*t + theta))\n",
    "    return signal\n",
    "\n",
    "def make_noise(sigma2, m):\n",
    "    noise_scaling = np.sqrt(sigma2/2)\n",
    "    # noise is complex valued\n",
    "    noise  = noise_scaling*np.random.randn(m) + 1j*noise_scaling*np.random.randn(m)\n",
    "    return noise\n",
    "\n",
    "def make_noisy_signal(w,theta,SNRdb,m):\n",
    "    sigma2 = get_sigma2_from_snrdb(SNRdb)\n",
    "    signal = make_signal(w,theta,m)\n",
    "    noise  = make_noise(sigma2,m)\n",
    "    return signal + noise\n",
    "\n",
    "def make_signal_random(w,theta, N, m, inds):\n",
    "    sig = make_signal(w, theta, N)\n",
    "    #chosen_indices = np.sort(np.random.choice(range(N), size=m, replace=False))\n",
    "    return np.take(sig, inds)\n",
    "\n",
    "# N = divisor of w0\n",
    "# m = num samples\n",
    "def make_batch_noisy(batch_size, SNRdb, N, m, binary=False):\n",
    "    signals, freqs = [], []\n",
    "    for i in range(batch_size):\n",
    "        freq = np.random.randint(0, N)\n",
    "        w = (2 * np.pi * freq / N) % (2 * np.pi)\n",
    "        sig = make_noisy_signal(w, 0, SNRdb, m)\n",
    "        signals.append(sig)\n",
    "        freqs.append(freq)\n",
    "    if binary:\n",
    "        return signals, make_binary(freqs, N), one_hot(N, batch_size, freqs)\n",
    "    return signals, one_hot(N, batch_size, freqs)\n",
    "\n",
    "## GENERAL UTILS\n",
    "\n",
    "def hamming(pred, act):\n",
    "    pred = np.array(pred)\n",
    "    act = np.array(act)\n",
    "    return np.count_nonzero(pred != act)\n",
    "\n",
    "def make_binary(freqs, N):\n",
    "    w = math.ceil(np.log2(N))\n",
    "    return [[int(a) for a in list(np.binary_repr(f, width=w))] for f in freqs] \n",
    "\n",
    "def convert_bits(bits, base):\n",
    "    val = 0\n",
    "    for i in range(len(bits)):\n",
    "        val += bits[len(bits) - 1 - i] * (base**i)\n",
    "    return val\n",
    "\n",
    "def convert_int_to_bits(num, base, exp):\n",
    "    bits_base = np.base_repr(num, base)\n",
    "    bits_base = [int(a) for a in bits_base]\n",
    "    bits_base = [0] * (exp - len(bits_base)) + bits_base \n",
    "    return bits_base\n",
    "\n",
    "def get_bits_for_int(num, bases, exps):\n",
    "    first = convert_int_to_bits(num % (bases[0] ** exps[0]), bases[0], exps[0])\n",
    "    second = first = convert_int_to_bits(num % (bases[1] ** exps[1]), bases[1], exps[1])\n",
    "    return [first, second]\n",
    "\n",
    "def get_hamming(freq_bits, pred_bits):\n",
    "    return [hamming(freq_bits[0], pred_bits[0]), hamming(freq_bits[1], pred_bits[1])]\n",
    "\n",
    "def one_hot(N, batch_size, freqs):\n",
    "    freqs_one_hot = np.zeros((batch_size, N))\n",
    "    freqs_one_hot[np.arange(batch_size), freqs] = 1\n",
    "    return freqs_one_hot\n",
    "\n",
    "def chinese_remainder(n, a):\n",
    "    sum = 0\n",
    "    prod = reduce(lambda a, b: a*b, n)\n",
    "    for n_i, a_i in zip(n, a):\n",
    "        p = prod / n_i\n",
    "        sum += a_i * mul_inv(p, n_i) * p\n",
    "    return int(sum % prod)\n",
    " \n",
    " \n",
    " \n",
    "def mul_inv(a, b):\n",
    "    b0 = b\n",
    "    x0, x1 = 0, 1\n",
    "    if b == 1: return 1\n",
    "    while a > 1:\n",
    "        q = a // b\n",
    "        a, b = b, a%b\n",
    "        x0, x1 = x1 - q * x0, x0\n",
    "    if x1 < 0: x1 += b0\n",
    "    return x1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KAY UTILITIES\n",
    "\n",
    "def kay_weights(N):\n",
    "    scaling = (3.0/2)*N/(N**2 - 1)\n",
    "    \n",
    "    w = [1 - ((i - (N/2 - 1))/(N/2))**2 for i in range(N-1)]\n",
    "    \n",
    "    return scaling*np.array(w)\n",
    "\n",
    "def kays_method(my_signal):\n",
    "    N = len(my_signal)\n",
    "    w = kay_weights(N)\n",
    "    \n",
    "    angle_diff = np.angle(np.conj(my_signal[0:-1])*my_signal[1:])\n",
    "    need_to_shift = np.any(angle_diff < -np.pi/2)\n",
    "    if need_to_shift:    \n",
    "        neg_idx = angle_diff < 0\n",
    "        angle_diff[neg_idx] += np.pi*2\n",
    "    \n",
    "    return w.dot(angle_diff)\n",
    "\n",
    "def kays_singleton_accuracy(test_signals, test_freqs, N):\n",
    "    diffs = [s - make_signal(kays_method(s), 0, N) for s in test_signals]\n",
    "    thresh, single_acc, other_acc, best_thresh = 0.0, 0, 0, 0\n",
    "    best = 0\n",
    "    for i in range(150):\n",
    "        vals = [(sum(np.absolute(s)) / N) < thresh for s in diffs]\n",
    "        corr = [1 for i in range(len(test_freqs)) if (test_freqs[i] == [0, 1, 0] and vals[i] == 1) or ((test_freqs[i] != [0, 1, 0] and vals[i] == 0))]\n",
    "        corr = sum(corr)\n",
    "        #single = sum([vals[d] for d in range(len(vals)) if test_freqs[d] == [0, 1, 0]]) / len([vals[d] for d in range(len(vals)) if test_freqs[d] == [0, 1, 0]])\n",
    "        #other = sum([not vals[d] for d in range(len(vals)) if test_freqs[d] != [0, 1, 0]]) / len([vals[d] for d in range(len(vals)) if test_freqs[d] != [0, 1, 0]])        \n",
    "        #if single*2 + other > single_acc*2 + other_acc and single > 0.2 and other > 0.2:\n",
    "        #    single_acc = single\n",
    "        #    other_acc = other\n",
    "        #    best_thresh = thresh\n",
    "        if corr > best:\n",
    "            best = corr\n",
    "            best_thresh = thresh\n",
    "        thresh += 0.05\n",
    "    print('thresh: ', best_thresh)\n",
    "    return best / len(test_signals)\n",
    "\n",
    "def test_kays(signals, freqs, N):\n",
    "    count = 0\n",
    "    for sig, freq in zip(signals, freqs):\n",
    "        res = kays_method(sig)\n",
    "        res = round(res * N / (2 * np.pi))\n",
    "        if np.argmax(freq) == res:\n",
    "            count += 1\n",
    "    return count / len(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SINGLETON UTILITIES\n",
    "\n",
    "def make_batch_singleton(batch_size, SNRdb, N, m, default=-1): # 0 = zero, 1 = single, 2 = multi\n",
    "    signals, freqs = [], []\n",
    "    sigma2 = get_sigma2_from_snrdb(SNRdB)\n",
    "    for i in range(batch_size):\n",
    "        val = np.random.poisson(0.79)\n",
    "        if default >= 0:\n",
    "            val = default\n",
    "        if val == 0:\n",
    "            signals.append(make_noise(0, m))\n",
    "            freqs.append([1, 0, 0])\n",
    "        if val == 1:\n",
    "            signals.append(make_noisy_signal(2 * np.pi * np.random.randint(0, N) / N, 0, SNRdB, m))\n",
    "            freqs.append([0, 1, 0])\n",
    "        if val >= 2:\n",
    "            signal = make_signal(2 * np.pi * np.random.randint(0, N) / N, 0, m)\n",
    "            for i in range(val - 1):\n",
    "                signal += make_signal(2 * np.pi * np.random.randint(0, N) / N, 0, m)\n",
    "            signals.append(signal + make_noise(sigma2, m))\n",
    "            freqs.append([0, 0, 1])\n",
    "    return signals, freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLE UTILITIES\n",
    "\n",
    "def test_mle(signals, freqs, N, m):\n",
    "    count = 0\n",
    "    for sig, freq in zip(signals, freqs):\n",
    "        cleans = [make_signal(np.pi * 2 * w / N, 0, m) for w in range(N)]\n",
    "        dots = [np.absolute(np.vdot(sig, clean)) for clean in cleans]\n",
    "        if np.argmax(dots) == np.argmax(freq):\n",
    "            count += 1\n",
    "    return count / len(signals)\n",
    "\n",
    "def test_noisy_mle(N, m, signals, freqs):\n",
    "    count = 0  \n",
    "    '''imag_signals = []\n",
    "    for index in range(len(signals)):\n",
    "        sig = signals[index]\n",
    "        imag_sig = [(sig[i] + 1j*sig[i+1]) for i in np.arange(len(sig), step=2)]\n",
    "        imag_signals.append(imag_sig)'''\n",
    "    cleans = [make_signal(2*np.pi*i/N, 0, m) for i in range(N)]\n",
    "                     \n",
    "    for index in range(len(signals)):\n",
    "        dots = [np.absolute(np.vdot(signals[index], cleans[i])) for i in range(N)]\n",
    "        if np.argmax(freqs[index]) == np.argmax(dots):\n",
    "            #print(np.argmax(dots))\n",
    "            count += 1\n",
    "    return count / len(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN UTILITIES\n",
    "\n",
    "# inds=random indices used to test mle\n",
    "def make_noisy_lohi(SNRdb, N, m, freq, inds, starts):\n",
    "    signals, vals = [], []\n",
    "    steps = int(np.log2(N))\n",
    "    w = (2 * np.pi * freq / N) % (2 * np.pi)\n",
    "    sig = make_noisy_signal(w, 0, SNRdb, N)\n",
    "    #start = 0\n",
    "    for i in range(int(np.log2(N))):\n",
    "        #start = start + np.random.randint(N // 4) if i > 0 else 0\n",
    "        signals.append([sig[(starts[i] + a * (2**i)) % N] for a in range(m)])\n",
    "        if (freq * (2**i)) % (N) < N / 2:\n",
    "            vals.append([0])\n",
    "        else:\n",
    "            vals.append([1])\n",
    "    return signals, vals, np.take(sig, inds)\n",
    "\n",
    "# for general base\n",
    "# inds=random indices used to test mle\n",
    "def make_noisy_lohi2(SNRdb, N, m, freq, inds, starts, base):\n",
    "    signals, vals = [], []\n",
    "    steps = int(np.log(N) / np.log(base))\n",
    "    w = (2 * np.pi * freq / N) % (2 * np.pi)\n",
    "    sig = make_noisy_signal(w, 0, SNRdb, N)\n",
    "    #start = 0\n",
    "    for i in range(steps):\n",
    "        #start = start + np.random.randint(N // 4) if i > 0 else 0\n",
    "        signals.append([sig[(starts[i] + a * (base**i)) % N] for a in range(m)])\n",
    "        freq_array = [0] * base\n",
    "        freq_array[((freq * (base**i) % N) * base) // N] = 1\n",
    "        vals.append(freq_array)\n",
    "    return signals, vals, np.take(sig, inds)\n",
    "\n",
    "# N = divisor of w0\n",
    "# m = num samples\n",
    "# starts = shift for each subsequent sample\n",
    "def make_batch_noisy_lohi(batch_size, SNRdb, N, m, inds, starts=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]):\n",
    "    freqs = []\n",
    "    randoms = []\n",
    "    freqs.append(np.random.randint(0, N))\n",
    "    test_signals, test_freqs, test_rand = make_noisy_lohi(SNRdB, N, m, freqs[-1], inds, starts)\n",
    "    randoms.append(test_rand)\n",
    "    for i in range(1, batch_size):\n",
    "        freqs.append(np.random.randint(0, N))\n",
    "        a, b, c = make_noisy_lohi(SNRdB, N, m, freqs[-1], inds, starts)\n",
    "        test_signals.extend(a)\n",
    "        test_freqs.extend(b)\n",
    "        randoms.append(c)\n",
    "    return test_signals, test_freqs, freqs, randoms\n",
    "\n",
    "# for general base\n",
    "# N = divisor of w0\n",
    "# m = num samples\n",
    "# starts = shift for each subsequent sample\n",
    "def make_batch_noisy_lohi(batch_size, SNRdb, N, m, inds, base, starts=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]):\n",
    "    freqs = []\n",
    "    randoms = []\n",
    "    freqs.append(np.random.randint(0, N))\n",
    "    test_signals, test_freqs, test_rand = make_noisy_lohi2(SNRdB, N, m, freqs[-1], inds, starts, base)\n",
    "    randoms.append(test_rand)\n",
    "    for i in range(1, batch_size):\n",
    "        freqs.append(np.random.randint(0, N))\n",
    "        a, b, c = make_noisy_lohi2(SNRdB, N, m, freqs[-1], inds, starts, base)\n",
    "        test_signals.extend(a)\n",
    "        test_freqs.extend(b)\n",
    "        randoms.append(c)\n",
    "    return test_signals, test_freqs, freqs, randoms\n",
    "\n",
    "def test_all_1bit(bits, N, m, signal):\n",
    "    vals = []\n",
    "    new_signal = np.zeros((m))\n",
    "    new_signal = signal[:, 0] + 1j*signal[:, 1]\n",
    "    signal = new_signal\n",
    "    min_ind = convert_bits(bits)\n",
    "    sig = make_signal((convert_bits(bits) * 2*np.pi/N), 0, m)\n",
    "    min_val = np.vdot(sig - signal, sig - signal)\n",
    "    vals.append(min_val)\n",
    "    for i in range((len(bits) // 2)): # because less significant bits have more wiggle - easier to cause false error\n",
    "        bits[i] = abs(bits[i] - 1)\n",
    "        sig = make_signal((convert_bits(bits) * 2*np.pi/N), 0, m)\n",
    "        resid = np.vdot(sig - signal, sig - signal)\n",
    "        vals.append(resid)\n",
    "        if resid < min_val: \n",
    "            min_val = resid\n",
    "            min_ind = convert_bits(bits)\n",
    "        bits[i] = abs(bits[i] - 1)\n",
    "    #print('thresh: ', min_ind)\n",
    "    #print(vals)\n",
    "    #print(min_ind == convert_bits(bits))\n",
    "    return min_ind\n",
    "\n",
    "def test_all_1bit_random(bits, N, m, signal, inds): # try set of all combined measurements mle\n",
    "    vals = []\n",
    "    total_time = 0\n",
    "    #new_signal = np.zeros((m))\n",
    "    #new_signal = signal[:, 0] + 1j*signal[:, 1]\n",
    "    #signal = new_signal\n",
    "    min_ind = convert_bits(bits)\n",
    "    sig = make_signal_random((convert_bits(bits) * 2*np.pi/N), 0, N, m, inds)\n",
    "    t_start = time.time()\n",
    "    min_val = np.absolute(np.vdot(sig, signal))\n",
    "    total_time += (time.time() - t_start)\n",
    "    vals.append(min_val)\n",
    "    for i in range((len(bits))): # because less significant bits have more wiggle - easier to cause false error\n",
    "        bits[i] = abs(bits[i] - 1)\n",
    "        sig = make_signal_random((convert_bits(bits) * 2*np.pi/N), 0, N, m, inds)\n",
    "        t_start = time.time()\n",
    "        resid = np.absolute(np.vdot(sig, signal))\n",
    "        vals.append(resid)\n",
    "        if resid > min_val: \n",
    "            min_val = resid\n",
    "            min_ind = convert_bits(bits)\n",
    "        total_time += (time.time() - t_start)\n",
    "        bits[i] = abs(bits[i] - 1)\n",
    "    #print('thresh: ', min_ind)\n",
    "    #print(vals)\n",
    "    #print(min_ind == convert_bits(bits))\n",
    "    return min_ind, total_time\n",
    "\n",
    "# want to generate train, test data\n",
    "def generate_data_dicts(N, ms, bases, exps, dict_size, batch_size, SNRdB, indices):\n",
    "    dict1, dict2 = {}, {}\n",
    "    inds1, inds2 = [], []\n",
    "    sigma2 = get_sigma2_from_snrdb(SNRdB)\n",
    "    for i in range(exps[0]):\n",
    "        inds1.append([(k * (bases[1] ** exps[1]) * (bases[0] ** i)) % N for k in range(ms[0])])\n",
    "    for i in range(exps[1]):\n",
    "        inds2.append([(k * (bases[0] ** exps[0]) * (bases[1] ** i)) % N for k in range(ms[1])])\n",
    "    for i in range(dict_size):\n",
    "        sigs1, sigs2 = [], []\n",
    "        freqs1, freqs2 = [], []\n",
    "        randoms, orig_freqs = [], []\n",
    "        for k in range(batch_size):\n",
    "            curr_freq = np.random.randint(0, N)\n",
    "            w = (2 * np.pi * curr_freq / N) % (2 * np.pi)\n",
    "            orig_freqs.append(curr_freq)\n",
    "            signal_values = {}\n",
    "            for j in range(len(inds1)):\n",
    "                for ind in inds1[j]:\n",
    "                    if ind not in signal_values:\n",
    "                        signal_values[ind] = np.exp(1j*(w*ind)) + make_noise(sigma2, 1)[0]\n",
    "                sigs1.append([signal_values[ind] for ind in inds1[j]])\n",
    "                freq_one_hot = [0] * bases[0]\n",
    "                freq_one_hot[((curr_freq * (bases[1]**exps[1]) * (bases[0] ** j) % N) * bases[0]) // N] = 1\n",
    "                freqs1.append(freq_one_hot)\n",
    "                \n",
    "            for j in range(len(inds2)):\n",
    "                for ind in inds2[j]:\n",
    "                    if ind not in signal_values:\n",
    "                        signal_values[ind] = np.exp(1j*(w*ind)) + make_noise(sigma2, 1)[0]\n",
    "                sigs2.append([signal_values[ind] for ind in inds2[j]])\n",
    "                freq_one_hot = [0] * bases[1]\n",
    "                freq_one_hot[((curr_freq * (bases[0]**exps[0]) * (bases[1] ** j) % N) * bases[1]) // N] = 1\n",
    "                freqs2.append(freq_one_hot)\n",
    "                \n",
    "            for ind in indices:\n",
    "                if ind not in signal_values:\n",
    "                    signal_values[ind] = np.exp(1j*(w*ind)) + make_noise(sigma2, 1)[0]\n",
    "            randoms.append([signal_values[ind] for ind in indices])\n",
    "        dict1[i] = (sigs1, freqs1, randoms, orig_freqs)\n",
    "        dict2[i] = (sigs2, freqs2, randoms, orig_freqs)\n",
    "    return (dict1, dict2)\n",
    "            \n",
    "\n",
    "def train_nn(N, m, train_dict, batch_size, dict_size, num_classes=2, layer=3, num_iter=10000, learning_rate=0.005):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = tf.placeholder(\"float\", [None, m, 2], name = 'X')\n",
    "    Y = tf.placeholder(\"float\", [None, num_classes], name = 'Y')\n",
    "\n",
    "    # weights for frequency classification\n",
    "    weights = {i: tf.Variable(tf.random_normal([3, 2, 2]), name='w{}'.format(i)) for i in range(1, layer+1)} # increase out channels, less layers\n",
    "    weights[0] = tf.Variable(tf.random_normal([5, 2, 2]), name='w0')\n",
    "    weights['out'] = tf.Variable(tf.random_normal([(m - 4 - (2 * layer)) * 2, num_classes]), name='wout')\n",
    "    biases = {i: tf.Variable(tf.random_normal([2]), name='b{}'.format(i)) for i in range(layer+1)}\n",
    "    biases['out'] = tf.Variable(tf.random_normal([num_classes]), name='bout')\n",
    "    \n",
    "\n",
    "\n",
    "    def neural_net(x):\n",
    "        layer_1 = tf.add(tf.nn.conv1d(x, weights[0], 1, 'VALID'), biases[0])\n",
    "        hidden_1 = tf.nn.relu(layer_1)\n",
    "        for i in range(1, layer+1):\n",
    "            layer_1 = tf.add(tf.nn.conv1d(hidden_1, weights[i], 1, 'VALID'), biases[i]) # no padding\n",
    "            hidden_1 = tf.nn.relu(layer_1) # try: elu, leaky\n",
    "            ###hidden_1 = tf.layers.batch_normalizationf(hidden_1)\n",
    "            ### instance normalize\n",
    "        hidden_3 = tf.reshape(hidden_1, [batch_size, -1])\n",
    "        out_layer = tf.matmul(hidden_3, weights['out']) + biases['out']\n",
    "        return out_layer\n",
    "\n",
    "\n",
    "\n",
    "    # Construct model\n",
    "    \n",
    "    logits = neural_net(X)\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    losses, accuracies = [], []\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=Y))  \n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "    # Evaluate model\n",
    "    pred_class = tf.argmax(prediction, 1)\n",
    "    tf.identity(pred_class, name=\"pred_class_op\")\n",
    "    correct_pred = tf.equal(pred_class, tf.argmax(Y, 1))\n",
    "    tf.identity(correct_pred, name=\"correct_pred_op\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # Initialize the variables (i.e. assign their default value)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start training\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "        # print(\"Training Started\")\n",
    "\n",
    "        for step in range(1, num_iter + 1):\n",
    "            batch_x, batch_y, rands, freqs = train_dict[step % dict_size]\n",
    "            batch_x_pair = np.zeros((batch_size, m, 2))\n",
    "            batch_x_pair[:, :, 0] = np.real(batch_x)\n",
    "            batch_x_pair[:, :, 1] = np.imag(batch_x)\n",
    "\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(train_op, feed_dict={X: batch_x_pair, Y: batch_y})\n",
    "\n",
    "            if step % 500 == 0:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc, pred = sess.run([loss_op, accuracy, prediction], feed_dict={X: batch_x_pair,\n",
    "                                                                    Y: batch_y})                                           \n",
    "\n",
    "                accuracies.append(acc)\n",
    "                losses.append(loss)\n",
    "                print(\"Freq Iter \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                    \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                    \"{:.3f}\".format(acc))\n",
    "        print(\"Training Finished\")\n",
    "        #saver.save(sess, './N:{}_m:{}_base:{}'.format(N, m, num_classes))\n",
    "        saver.save(sess, './N{}m{}base{}'.format(N, m, num_classes))\n",
    "    print('done')\n",
    "    \n",
    "        \n",
    "def test_nn(N, m, train_dict, dict_size, batch_size, base, exp):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.import_meta_graph('N{}m{}base{}.meta'.format(N, m, base)) # fix to actual checkpoint formatted above\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "        X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "        Y = tf.get_default_graph().get_tensor_by_name(\"Y:0\")\n",
    "        pred_class = tf.get_default_graph().get_tensor_by_name(\"pred_class_op:0\")\n",
    "        all_preds = []\n",
    "        all_actuals = []\n",
    "        total_time = 0\n",
    "        for i in range(dict_size):\n",
    "            batch_x, batch_y, rands, freqs = train_dict[i]\n",
    "            batch_x_pair = np.zeros((batch_size, m, 2))\n",
    "            batch_x_pair[:, :, 0] = np.real(batch_x)\n",
    "            batch_x_pair[:, :, 1] = np.imag(batch_x)\n",
    "            start_time = time.time()\n",
    "            preds = sess.run(pred_class, feed_dict={X: batch_x_pair, Y: batch_y})\n",
    "            end_time = time.time()\n",
    "            total_time += end_time - start_time\n",
    "            acts = np.array([np.argmax(a) for a in batch_y])\n",
    "            #if list(preds) != [np.argmax(a) for a in batch_y]:\n",
    "            #print(preds, np.array([np.argmax(a) for a in batch_y]))\n",
    "            pred_vals = [convert_bits(preds[exp * i : (exp + 1) * i], base) for i in range(batch_size // exp)]\n",
    "            actual_vals = [convert_bits(acts[exp * i : (exp + 1) * i], base) for i in range(batch_size // exp)]\n",
    "            #print(pred_vals, actual_vals)\n",
    "            all_preds.append(preds)\n",
    "            all_actuals.append(acts)\n",
    "            #else:\n",
    "            #    print('good')\n",
    "        \n",
    "        \n",
    "    return (total_time, all_preds, all_actuals)\n",
    "    \n",
    "    # do timing and accuracy tests\n",
    "    \n",
    "def determine_freq(N, bases, exps, freqs1, freqs2):\n",
    "    first = convert_bits(freqs1, bases[0])\n",
    "    second = convert_bits(freqs2, bases[1])\n",
    "    guess = chinese_remainder([bases[0] ** exps[0], bases[1] ** exps[1]], [first, second])\n",
    "    return (0, guess, (freqs1, freqs2))\n",
    "\n",
    "def determine_freq_full(N, bases, exps, freqs1, freqs2, rands, indices):\n",
    "    all_firsts = set()\n",
    "    all_firsts.add(convert_bits(freqs1, bases[0]))\n",
    "    for i in range(exps[0]):\n",
    "        bits = np.copy(freqs1)\n",
    "        for j in range(bases[0]):\n",
    "            bits[i] = j\n",
    "            all_firsts.add(convert_bits(bits, bases[0]))\n",
    "    firsts = list(all_firsts) * ((bases[1] - 1) * exps[1] + 1)\n",
    "    all_seconds = set()\n",
    "    all_seconds.add(convert_bits(freqs2, bases[1]))\n",
    "    for i in range(exps[1]):\n",
    "        bits = np.copy(freqs2)\n",
    "        for j in range(bases[1]):\n",
    "            bits[i] = j\n",
    "            all_seconds.add(convert_bits(bits, bases[1]))\n",
    "    seconds = []\n",
    "    for i in all_seconds:\n",
    "        seconds.extend([i] * ((bases[0] - 1) * exps[0] + 1))\n",
    "    max_dot, best_freq = 0, 0\n",
    "    total_time = 0\n",
    "    for first, second in zip(firsts, seconds):\n",
    "        freq = chinese_remainder([bases[0] ** exps[0], bases[1] ** exps[1]], [first, second])\n",
    "        w = 2 * np.pi * freq / N\n",
    "        random_sig = [np.exp(1j*(w*t)) for t in indices]\n",
    "        t_start = time.time()\n",
    "        dot_product = np.absolute(np.vdot(random_sig, rands))\n",
    "        if dot_product > max_dot:\n",
    "            max_dot = dot_product\n",
    "            best_freq = freq\n",
    "        t_end = time.time()\n",
    "        total_time += t_end - t_start\n",
    "    bits_1 = convert_int_to_bits(best_freq % (bases[0] ** exps[0]), bases[0], exps[0])\n",
    "    bits_2 = convert_int_to_bits(best_freq % (bases[1] ** exps[1]), bases[1], exps[1])\n",
    "    return (total_time, best_freq, (bits_1, bits_2))\n",
    "        \n",
    "    \n",
    "    \n",
    "def get_final_frequency(N, train_dict_1, train_dict_2, dict_size, batch_size, bases, exps, indices, all_preds, all_acts):\n",
    "    all_predictions = {} # (freq, (bits1, bits2)) for each batch for no error correcting \n",
    "    all_predictions_full = {} # (freq, (bits1, bits2)) for each batch for full 1 bit error correcting\n",
    "    total_time, total_time_full = 0, 0\n",
    "    for i in range(dict_size):\n",
    "        batch_x1, batch_y1, rands1, freqs1 = train_dict_1[i]\n",
    "        batch_x2, batch_y2, rands2, freqs2 = train_dict_2[i]\n",
    "        predictions, predictions_full = [], []\n",
    "        for j in range(batch_size):\n",
    "            pred = determine_freq(N, bases, exps, all_preds[0][i][exps[0] * j : exps[0] * (j+1)], all_preds[1][i][exps[1] * j : exps[1] * (j+1)])\n",
    "            pred_full = determine_freq_full(N, bases, exps, all_preds[0][i][exps[0] * j : exps[0] * (j+1)], all_preds[1][i][exps[1] * j : exps[1] * (j+1)], rands1[j], indices)\n",
    "            predictions.append(pred[1:])\n",
    "            predictions_full.append(pred_full[1:])\n",
    "            total_time += pred[0]\n",
    "            total_time_full += pred_full[0]\n",
    "        #predictions = [determine_freq(N, bases, exps, all_preds[0][i][exps[0] * j : exps[0] * (j+1)], all_preds[1][i][exps[1] * j : exps[1] * (j+1)]) for j in range(batch_size)]\n",
    "        #predictions_full = [determine_freq_full(N, bases, exps, all_preds[0][i][exps[0] * j : exps[0] * (j+1)], all_preds[1][i][exps[1] * j : exps[1] * (j+1)], rands1[j], indices) for j in range(batch_size)]\n",
    "        \n",
    "        \n",
    "        #determine_freq(N, bases, exps, all_acts[0][i][exps[0] * j : exps[0] * (j+1)], all_acts[1][i][exps[1] * j : exps[1] * (j+1)])\n",
    "        for j in range(batch_size):\n",
    "            if predictions[j][0] != freqs1[j] and predictions_full[j][0] != freqs1[j]:\n",
    "                print('guess (small):', predictions[j][0], 'guess (full):', predictions_full[j][0], 'actual:', freqs1[j])\n",
    "            elif predictions_full[j][0] != freqs1[j]:\n",
    "                print('guess (full):', predictions_full[j][0], 'actual:', freqs1[j])\n",
    "            elif predictions[j][0] != freqs1[j]:\n",
    "                print('guess (small):', predictions[j][0], 'actual:', freqs1[j])\n",
    "        all_predictions[i] = predictions\n",
    "        all_predictions_full[i] = predictions_full\n",
    "            \n",
    "    ## add all times together\n",
    "    print('done')\n",
    "    return (all_predictions, total_time), (all_predictions_full, total_time_full)\n",
    "        \n",
    "    \n",
    "# returns (test_dict_1, test_dict_2), which are of size dict_sizes[0] and have at each index: batch_x, batch_y, rands, freqs\n",
    "#         (all_predictions, total_time), which is of size dict_sizes[1] and have at each index: freq, (bits_1, bits_2), and then the total time by method 1 (no error correcting)\n",
    "#         (all_predictions_full, total_time_full), which is same as above for method 2 (1 bit comprehensive error correcting using mle)\n",
    "def frequency_detection(ms, bases, exps, dict_sizes, batch_size, SNRdB, num_iters=5000):\n",
    "    tf.reset_default_graph()\n",
    "    N = (bases[0] ** exps[0]) * (bases[1] ** exps[1])\n",
    "    indices = np.sort(np.random.choice(range(N), size=ms[0], replace=False))\n",
    "    d1, d2 = generate_data_dicts(N, ms, bases, exps, dict_sizes[0], batch_size, SNRdB, indices)\n",
    "    t1, t2 = generate_data_dicts(N, ms, bases, exps, dict_sizes[1], batch_size, SNRdB, indices)\n",
    "    train_nn(N, ms[0], d1, batch_size * exps[0], dict_sizes[0], num_classes=bases[0], layer=3, num_iter=num_iters)\n",
    "    time_feedfwd1, allp1, alla1 = test_nn(N, ms[0], t1, dict_sizes[1], batch_size * exps[0], bases[0], exps[0])\n",
    "    train_nn(N, ms[1], d2, batch_size * exps[1], dict_sizes[0], num_classes=bases[1], layer=3, num_iter=num_iters)\n",
    "    time_feedfwd2, allp2, alla2 = test_nn(N, ms[1], t2, dict_sizes[1], batch_size * exps[1], bases[1], exps[1])\n",
    "    (all_predictions, total_time), (all_predictions_full, total_time_full) = get_final_frequency(N, t1, t2, dict_sizes[1], batch_size, bases, exps, indices, [allp1, allp2], [alla1, alla2])\n",
    "    return (t1, t2), (all_predictions, total_time + time_feedfwd1 + time_feedfwd2), (all_predictions_full, total_time_full + time_feedfwd1 + time_feedfwd2)\n",
    "\n",
    "def calculate_accuracy(t1, all_preds, dict_size, batch_size):\n",
    "    correct = 0\n",
    "    for i in range(dict_size):\n",
    "        batch_x, batch_y, rands, freqs = t1[i]\n",
    "        for j in range(batch_size):\n",
    "            if all_preds[i][j][0] == freqs[j]:\n",
    "                correct += 1\n",
    "    return correct / (dict_size * batch_size)\n",
    "\n",
    "def test_time_scaling():\n",
    "    ms, bases, exps, dict_sizes, batch_size, SNRdB = [25, 25], [2, 3], [5, 5], [100, 3], 5, 8\n",
    "    (t1, t2), (all_preds, time_small), (all_preds_full, time_full) = frequency_detection(ms, bases, exps, dict_sizes, batch_size, SNRdB)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq Iter 500, Minibatch Loss= 0.1900, Training Accuracy= 0.920\n",
      "Freq Iter 1000, Minibatch Loss= 0.0360, Training Accuracy= 1.000\n",
      "Training Finished\n",
      "done\n",
      "INFO:tensorflow:Restoring parameters from ./N7776m25base2\n",
      "Freq Iter 500, Minibatch Loss= 0.6358, Training Accuracy= 0.760\n",
      "Freq Iter 1000, Minibatch Loss= 0.3947, Training Accuracy= 0.800\n",
      "Training Finished\n",
      "done\n",
      "INFO:tensorflow:Restoring parameters from ./N7776m25base3\n",
      "guess (small): 6671 guess (full): 2063 actual: 1127\n",
      "guess (small): 1461 actual: 21\n",
      "guess (small): 4510 actual: 1054\n",
      "guess (small): 5431 guess (full): 3253 actual: 1399\n",
      "guess (small): 4898 actual: 7490\n",
      "guess (small): 6597 actual: 1413\n",
      "guess (small): 2944 guess (full): 272 actual: 5056\n",
      "guess (small): 7325 actual: 2141\n",
      "guess (small): 4679 guess (full): 5159 actual: 1511\n",
      "done\n",
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "#test_time_scaling()\n",
    "ms, bases, exps, dict_sizes, batch_size, SNRdB = [25, 25], [2, 3], [5, 5], [100, 3], 5, 8\n",
    "(t1, t2), (all_preds, time_small), (all_preds_full, time_full) = frequency_detection(ms, bases, exps, dict_sizes, batch_size, SNRdB, num_iters=1000)\n",
    "print(calculate_accuracy(t1, all_preds_full, dict_sizes[1], batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "0.015990257263183594\n",
      "0.032866477966308594\n",
      "[7054, 6964, 3836, 245, 5953]\n",
      "[3103, 431, 2951, 6065, 944]\n",
      "[[1, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 0, 1, 1, 1], [1, 0, 0, 0, 1], [1, 0, 0, 0, 0]]\n",
      "[[2, 0, 2, 2, 1], [2, 0, 2, 2, 2], [0, 1, 0, 2, 2], [2, 2, 1, 2, 2], [2, 1, 2, 2, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(len(all_preds))\n",
    "print(len(all_preds_full))\n",
    "print(time_small)\n",
    "print(time_full)\n",
    "batch_x, batch_y, rands, freqs = t1[0]\n",
    "print(freqs)\n",
    "print([a[0] for a in all_preds_full[0]])\n",
    "print([list(a[1][0]) for a in all_preds_full[0]])\n",
    "print([list(a[1][1]) for a in all_preds_full[0]])\n",
    "#freqs, (bits1, bits2) = all_preds[0]\n",
    "#print(freqs, (bits1, bits2))\n",
    "#freqs, (bits1, bits2) = all_preds[0]\n",
    "#print(freqs, (bits1, bits2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = 8, 5\n",
    "N = (2**x) * (3**y)\n",
    "#freq = 1\n",
    "for freq in range(N):\n",
    "    sig2 = [((freq * (3**y) * (2**i) % N) * 2) // N for i in range(x)]\n",
    "    sig3 = [((freq * (2**x) * (3**i) % N) * 3) // N for i in range(y)]\n",
    "    int2, int3 = convert_bits(sig2, 2), convert_bits(sig3, 3)\n",
    "    if freq != (chinese_remainder([2**x, 3**y], [int2, int3])):\n",
    "        print(freq != (chinese_remainder([2**x, 3**y], [int2, int3])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N, ms, bases, exps, dict_size, batch_size, SNRdB, indices = 432, [6, 4], [2, 3], [4, 3], 100, 5, 8, [0, 1, 2, 3]\n",
    "#d1, d2 = generate_data_dicts(N, ms, bases, exps, dict_size, batch_size, SNRdB, indices)\n",
    "#sig1, freq1, rands1, origs1 = d1[0]\n",
    "#sig2, freq2, rands2, origs2 = d2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
