{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_signal(w,theta,n):\n",
    "    \"\"\"\n",
    "    Assumes normalized amplitude\n",
    "    \"\"\"\n",
    "    t = np.arange(n)\n",
    "    signal = np.exp(1j*(w*t + theta))\n",
    "    return signal\n",
    "\n",
    "def make_noise(sigma2,n):\n",
    "    noise_scaling = np.sqrt(sigma2/2)\n",
    "    # noise is complex valued\n",
    "    noise  = noise_scaling*np.random.randn(n) + 1j*noise_scaling*np.random.randn(n)\n",
    "    return noise\n",
    "\n",
    "def make_noisy_signal(w,theta,SNRdb,n):\n",
    "    sigma2 = get_sigma2_from_snrdb(SNRdb)\n",
    "    signal = make_signal(w,theta,n)\n",
    "    noise  = make_noise(sigma2,n)\n",
    "    return signal + noise\n",
    "\n",
    "# N = divisor of w0\n",
    "# m = num samples\n",
    "def make_batch_noisy(batch_size, SNRdb, N, m, binary=False):\n",
    "    signals, freqs = [], []\n",
    "    for i in range(batch_size):\n",
    "        freq = np.random.randint(0, N)\n",
    "        w = (2 * np.pi * freq / N) % (2 * np.pi)\n",
    "        sig = make_noisy_signal(w, 0, SNRdb, m)\n",
    "        signals.append(sig)\n",
    "        freqs.append(freq)\n",
    "    if binary:\n",
    "        return signals, make_binary(freqs, N), one_hot(N, batch_size, freqs)\n",
    "    return signals, one_hot(N, batch_size, freqs)\n",
    "\n",
    "def make_batch_singleton(batch_size, SNRdb, N, m):\n",
    "    signals, freqs = [], []\n",
    "    sigma2 = get_sigma2_from_snrdb(SNRdB)\n",
    "    for i in range(batch_size):\n",
    "        val = np.random.poisson(0.79)\n",
    "        if val == 0:\n",
    "            signals.append(make_noise(0, m))\n",
    "            freqs.append([1, 0, 0])\n",
    "        if val == 1:\n",
    "            signals.append(make_noisy_signal(2 * np.pi * np.random.randint(0, N) / N, 0, SNRdB, m))\n",
    "            freqs.append([0, 1, 0])\n",
    "        if val >= 2:\n",
    "            signal = make_signal(2 * np.pi * np.random.randint(0, N) / N, 0, m)\n",
    "            for i in range(val - 1):\n",
    "                signal += make_signal(2 * np.pi * np.random.randint(0, N) / N, 0, m)\n",
    "            signals.append(signal + make_noise(sigma2, m))\n",
    "            freqs.append([0, 0, 1])\n",
    "    return signals, freqs\n",
    "\n",
    "def get_sigma2_from_snrdb(SNR_db):\n",
    "    return 10**(-SNR_db/10)\n",
    "\n",
    "def kay_weights(N):\n",
    "    scaling = (3.0/2)*N/(N**2 - 1)\n",
    "    \n",
    "    w = [1 - ((i - (N/2 - 1))/(N/2))**2 for i in range(N-1)]\n",
    "    \n",
    "    return scaling*np.array(w)\n",
    "\n",
    "def kays_method(my_signal):\n",
    "    N = len(my_signal)\n",
    "    w = kay_weights(N)\n",
    "    \n",
    "    angle_diff = np.angle(np.conj(my_signal[0:-1])*my_signal[1:])\n",
    "    need_to_shift = np.any(angle_diff < -np.pi/2)\n",
    "    if need_to_shift:    \n",
    "        neg_idx = angle_diff < 0\n",
    "        angle_diff[neg_idx] += np.pi*2\n",
    "    \n",
    "    return w.dot(angle_diff)\n",
    "\n",
    "def kays_singleton_accuracy(test_signals, test_freqs, N):\n",
    "    diffs = [s - make_signal(kays_method(s), 0, N) for s in test_signals]\n",
    "    thresh, single_acc, other_acc, best_thresh = 0.0, 0, 0, 0\n",
    "    best = 0\n",
    "    for i in range(150):\n",
    "        vals = [(sum(np.absolute(s)) / N) < thresh for s in diffs]\n",
    "        corr = [1 for i in range(len(test_freqs)) if (test_freqs[i] == [0, 1, 0] and vals[i] == 1) or ((test_freqs[i] != [0, 1, 0] and vals[i] == 0))]\n",
    "        corr = sum(corr)\n",
    "        #single = sum([vals[d] for d in range(len(vals)) if test_freqs[d] == [0, 1, 0]]) / len([vals[d] for d in range(len(vals)) if test_freqs[d] == [0, 1, 0]])\n",
    "        #other = sum([not vals[d] for d in range(len(vals)) if test_freqs[d] != [0, 1, 0]]) / len([vals[d] for d in range(len(vals)) if test_freqs[d] != [0, 1, 0]])        \n",
    "        #if single*2 + other > single_acc*2 + other_acc and single > 0.2 and other > 0.2:\n",
    "        #    single_acc = single\n",
    "        #    other_acc = other\n",
    "        #    best_thresh = thresh\n",
    "        if corr > best:\n",
    "            best = corr\n",
    "            best_thresh = thresh\n",
    "        thresh += 0.05\n",
    "    print('thresh: ', best_thresh)\n",
    "    return best / len(test_signals)\n",
    "\n",
    "def test_kays(signals, freqs, N):\n",
    "    count = 0\n",
    "    for sig, freq in zip(signals, freqs):\n",
    "        res = kays_method(sig)\n",
    "        res = round(res * N / (2 * np.pi))\n",
    "        if np.argmax(freq) == res:\n",
    "            count += 1\n",
    "    return count / len(signals)\n",
    "\n",
    "def test_mle(signals, freqs, N, m):\n",
    "    count = 0\n",
    "    for sig, freq in zip(signals, freqs):\n",
    "        cleans = [make_signal(np.pi * 2 * w / N, 0, m) for w in range(N)]\n",
    "        dots = [np.absolute(np.vdot(sig, clean)) for clean in cleans]\n",
    "        if np.argmax(dots) == np.argmax(freq):\n",
    "            count += 1\n",
    "    return count / len(signals)\n",
    "    \n",
    "def make_binary(freqs, N):\n",
    "    w = math.ceil(np.log2(N))\n",
    "    return [[int(a) for a in list(np.binary_repr(f, width=w))] for f in freqs] \n",
    "\n",
    "def binary_to_int(binary_string):\n",
    "    return tf.reduce_sum(\n",
    "    tf.cast(tf.reverse(tensor=binary_string, axis=[0]), dtype=tf.int64)\n",
    "    * 2 ** tf.range(tf.cast(tf.size(binary_string), dtype=tf.int64)))\n",
    "    '''y = 0\n",
    "    for i,j in enumerate(x):\n",
    "        y += j<<i\n",
    "    return y'''\n",
    "\n",
    "def hamming(pred, act):\n",
    "    return np.count_nonzero(pred != act)\n",
    "\n",
    "def one_hot(N, batch_size, freqs):\n",
    "    freqs_one_hot = np.zeros((batch_size, N))\n",
    "    freqs_one_hot[np.arange(batch_size), freqs] = 1\n",
    "    return freqs_one_hot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Finished for snr= 8\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.7000000000000001\n",
      "Testing Accuracy Kay: 0.932\n",
      "Training Finished for snr= 8\n",
      "Testing Accuracy Neural: 0.804\n",
      "thresh:  0.39999999999999997\n",
      "Testing Accuracy Kay: 0.952\n",
      "Training Finished for snr= 8\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.39999999999999997\n",
      "Testing Accuracy Kay: 0.939\n",
      "Training Finished for snr= 8\n",
      "Testing Accuracy Neural: 0.999\n",
      "thresh:  0.9000000000000002\n",
      "Testing Accuracy Kay: 0.949\n",
      "Training Finished for snr= 8\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.9500000000000003\n",
      "Testing Accuracy Kay: 0.95\n",
      "Training Finished for snr= 8\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.39999999999999997\n",
      "Testing Accuracy Kay: 0.931\n",
      "Training Finished for snr= 8\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.65\n",
      "Testing Accuracy Kay: 0.941\n",
      "Training Finished for snr= 8\n",
      "Testing Accuracy Neural: 0.98\n",
      "thresh:  0.8000000000000002\n",
      "Testing Accuracy Kay: 0.936\n",
      "Training Finished for snr= 8\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.39999999999999997\n",
      "Testing Accuracy Kay: 0.934\n",
      "Training Finished for snr= 8\n",
      "Testing Accuracy Neural: 0.446\n",
      "thresh:  0.9500000000000003\n",
      "Testing Accuracy Kay: 0.96\n",
      "Training Finished for snr= 6\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.49999999999999994\n",
      "Testing Accuracy Kay: 0.826\n",
      "Training Finished for snr= 6\n",
      "Testing Accuracy Neural: 0.992\n",
      "thresh:  0.7000000000000001\n",
      "Testing Accuracy Kay: 0.83\n",
      "Training Finished for snr= 6\n",
      "Testing Accuracy Neural: 0.428\n",
      "thresh:  0.8000000000000002\n",
      "Testing Accuracy Kay: 0.821\n",
      "Training Finished for snr= 6\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.9500000000000003\n",
      "Testing Accuracy Kay: 0.866\n",
      "Training Finished for snr= 6\n",
      "Testing Accuracy Neural: 0.998\n",
      "thresh:  0.8500000000000002\n",
      "Testing Accuracy Kay: 0.829\n",
      "Training Finished for snr= 6\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.9000000000000002\n",
      "Testing Accuracy Kay: 0.863\n",
      "Training Finished for snr= 6\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.9000000000000002\n",
      "Testing Accuracy Kay: 0.834\n",
      "Training Finished for snr= 6\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.7500000000000001\n",
      "Testing Accuracy Kay: 0.84\n",
      "Training Finished for snr= 6\n",
      "Testing Accuracy Neural: 0.996\n",
      "thresh:  0.65\n",
      "Testing Accuracy Kay: 0.842\n",
      "Training Finished for snr= 6\n",
      "Testing Accuracy Neural: 0.999\n",
      "thresh:  0.8000000000000002\n",
      "Testing Accuracy Kay: 0.842\n",
      "Training Finished for snr= 4\n",
      "Testing Accuracy Neural: 0.998\n",
      "thresh:  0.8500000000000002\n",
      "Testing Accuracy Kay: 0.714\n",
      "Training Finished for snr= 4\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.8000000000000002\n",
      "Testing Accuracy Kay: 0.71\n",
      "Training Finished for snr= 4\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.9000000000000002\n",
      "Testing Accuracy Kay: 0.698\n",
      "Training Finished for snr= 4\n",
      "Testing Accuracy Neural: 0.999\n",
      "thresh:  0.9000000000000002\n",
      "Testing Accuracy Kay: 0.716\n",
      "Training Finished for snr= 4\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.8000000000000002\n",
      "Testing Accuracy Kay: 0.705\n",
      "Training Finished for snr= 4\n",
      "Testing Accuracy Neural: 0.999\n",
      "thresh:  0.7500000000000001\n",
      "Testing Accuracy Kay: 0.691\n",
      "Training Finished for snr= 4\n",
      "Testing Accuracy Neural: 0.805\n",
      "thresh:  0.8500000000000002\n",
      "Testing Accuracy Kay: 0.713\n",
      "Training Finished for snr= 4\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.7500000000000001\n",
      "Testing Accuracy Kay: 0.718\n",
      "Training Finished for snr= 4\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.9000000000000002\n",
      "Testing Accuracy Kay: 0.694\n",
      "Training Finished for snr= 4\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.8500000000000002\n",
      "Testing Accuracy Kay: 0.683\n",
      "Training Finished for snr= 2\n",
      "Testing Accuracy Neural: 0.999\n",
      "thresh:  0.9500000000000003\n",
      "Testing Accuracy Kay: 0.657\n",
      "Training Finished for snr= 2\n",
      "Testing Accuracy Neural: 0.996\n",
      "thresh:  0.8000000000000002\n",
      "Testing Accuracy Kay: 0.654\n",
      "Training Finished for snr= 2\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.9000000000000002\n",
      "Testing Accuracy Kay: 0.656\n",
      "Training Finished for snr= 2\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.8500000000000002\n",
      "Testing Accuracy Kay: 0.657\n",
      "Training Finished for snr= 2\n",
      "Testing Accuracy Neural: 0.468\n",
      "thresh:  0.9000000000000002\n",
      "Testing Accuracy Kay: 0.661\n",
      "Training Finished for snr= 2\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.8000000000000002\n",
      "Testing Accuracy Kay: 0.629\n",
      "Training Finished for snr= 2\n",
      "Testing Accuracy Neural: 0.992\n",
      "thresh:  0.8500000000000002\n",
      "Testing Accuracy Kay: 0.652\n",
      "Training Finished for snr= 2\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.7500000000000001\n",
      "Testing Accuracy Kay: 0.674\n",
      "Training Finished for snr= 2\n",
      "Testing Accuracy Neural: 0.999\n",
      "thresh:  0.8500000000000002\n",
      "Testing Accuracy Kay: 0.668\n",
      "Training Finished for snr= 2\n",
      "Testing Accuracy Neural: 0.823\n",
      "thresh:  0.7500000000000001\n",
      "Testing Accuracy Kay: 0.643\n",
      "Training Finished for snr= 0\n",
      "Testing Accuracy Neural: 0.999\n",
      "thresh:  0.9000000000000002\n",
      "Testing Accuracy Kay: 0.656\n",
      "Training Finished for snr= 0\n",
      "Testing Accuracy Neural: 1.0\n",
      "thresh:  0.9000000000000002\n",
      "Testing Accuracy Kay: 0.643\n",
      "Training Finished for snr= 0\n",
      "Testing Accuracy Neural: 0.982\n",
      "thresh:  0.9500000000000003\n",
      "Testing Accuracy Kay: 0.637\n",
      "Training Finished for snr= 0\n",
      "Testing Accuracy Neural: 0.804\n",
      "thresh:  0.9500000000000003\n",
      "Testing Accuracy Kay: 0.653\n",
      "Training Finished for snr= 0\n",
      "Testing Accuracy Neural: 0.998\n",
      "thresh:  0.9500000000000003\n",
      "Testing Accuracy Kay: 0.66\n",
      "Training Finished for snr= 0\n",
      "Testing Accuracy Neural: 0.988\n",
      "thresh:  0.9500000000000003\n",
      "Testing Accuracy Kay: 0.662\n",
      "Training Finished for snr= 0\n",
      "Testing Accuracy Neural: 0.999\n",
      "thresh:  0.9000000000000002\n",
      "Testing Accuracy Kay: 0.637\n",
      "Training Finished for snr= 0\n",
      "Testing Accuracy Neural: 0.992\n",
      "thresh:  0.9000000000000002\n",
      "Testing Accuracy Kay: 0.675\n",
      "Training Finished for snr= 0\n",
      "Testing Accuracy Neural: 0.999\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.653\n",
      "Training Finished for snr= 0\n",
      "Testing Accuracy Neural: 0.986\n",
      "thresh:  0.9500000000000003\n",
      "Testing Accuracy Kay: 0.655\n",
      "Training Finished for snr= -2\n",
      "Testing Accuracy Neural: 0.816\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.645\n",
      "Training Finished for snr= -2\n",
      "Testing Accuracy Neural: 0.981\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.656\n",
      "Training Finished for snr= -2\n",
      "Testing Accuracy Neural: 0.993\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.639\n",
      "Training Finished for snr= -2\n",
      "Testing Accuracy Neural: 0.815\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.656\n",
      "Training Finished for snr= -2\n",
      "Testing Accuracy Neural: 0.998\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.641\n",
      "Training Finished for snr= -2\n",
      "Testing Accuracy Neural: 0.989\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.649\n",
      "Training Finished for snr= -2\n",
      "Testing Accuracy Neural: 0.472\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.648\n",
      "Training Finished for snr= -2\n",
      "Testing Accuracy Neural: 0.466\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.648\n",
      "Training Finished for snr= -2\n",
      "Testing Accuracy Neural: 0.985\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.625\n",
      "Training Finished for snr= -2\n",
      "Testing Accuracy Neural: 0.478\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.648\n",
      "Training Finished for snr= -4\n",
      "Testing Accuracy Neural: 0.438\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.642\n",
      "Training Finished for snr= -4\n",
      "Testing Accuracy Neural: 0.985\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.649\n",
      "Training Finished for snr= -4\n",
      "Testing Accuracy Neural: 0.96\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.645\n",
      "Training Finished for snr= -4\n",
      "Testing Accuracy Neural: 0.439\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.655\n",
      "Training Finished for snr= -4\n",
      "Testing Accuracy Neural: 0.932\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.646\n",
      "Training Finished for snr= -4\n",
      "Testing Accuracy Neural: 0.804\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.63\n",
      "Training Finished for snr= -4\n",
      "Testing Accuracy Neural: 0.957\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.65\n",
      "Training Finished for snr= -4\n",
      "Testing Accuracy Neural: 0.978\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.616\n",
      "Training Finished for snr= -4\n",
      "Testing Accuracy Neural: 0.464\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.654\n",
      "Training Finished for snr= -4\n",
      "Testing Accuracy Neural: 0.808\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.645\n",
      "Training Finished for snr= -6\n",
      "Testing Accuracy Neural: 0.926\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.635\n",
      "Training Finished for snr= -6\n",
      "Testing Accuracy Neural: 0.961\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.639\n",
      "Training Finished for snr= -6\n",
      "Testing Accuracy Neural: 0.436\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.633\n",
      "Training Finished for snr= -6\n",
      "Testing Accuracy Neural: 0.891\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.63\n",
      "Training Finished for snr= -6\n",
      "Testing Accuracy Neural: 0.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.652\n",
      "Training Finished for snr= -6\n",
      "Testing Accuracy Neural: 0.926\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.636\n",
      "Training Finished for snr= -6\n",
      "Testing Accuracy Neural: 0.826\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.611\n",
      "Training Finished for snr= -6\n",
      "Testing Accuracy Neural: 0.8\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.626\n",
      "Training Finished for snr= -6\n",
      "Testing Accuracy Neural: 0.483\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.66\n",
      "Training Finished for snr= -6\n",
      "Testing Accuracy Neural: 0.953\n",
      "thresh:  0.0\n",
      "Testing Accuracy Kay: 0.643\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seeing snr vs accuracy for singleton detection (kay vs nn)\n",
    "\n",
    "nn_accs = []\n",
    "kay_1s = []\n",
    "kay_2s = []\n",
    "snrs = [8, 6, 4, 2, 0, -2, -4, -6]\n",
    "\n",
    "for SNRdB in snrs:\n",
    "    \n",
    "    trial_nn = []\n",
    "    trial_kay = []\n",
    "    for _ in range(10):\n",
    "\n",
    "        N = 27000 #512\n",
    "        #SNRdB = 0\n",
    "        m = 300 #16\n",
    "\n",
    "        # Parameters\n",
    "        learning_rate = 0.005\n",
    "        num_iter = 8000\n",
    "        batch_size = 1000\n",
    "\n",
    "        # Network Parameters\n",
    "        num_classes = 3\n",
    "\n",
    "        # tf Graph input\n",
    "        X = tf.placeholder(\"float\", [None, m, 2])\n",
    "        Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "        # Store layers weight & bias\n",
    "        weights = {\n",
    "            'h1': tf.Variable(tf.random_normal([5, 2, 2])), # filtersize, in channels, outchannels\n",
    "            'out': tf.Variable(tf.random_normal([(m-4-2-2)*2, num_classes])),\n",
    "            'h2': tf.Variable(tf.random_normal([3, 2, 2])),\n",
    "            'h3': tf.Variable(tf.random_normal([3, 2, 2]))\n",
    "        }\n",
    "        biases = {\n",
    "            'b1': tf.Variable(tf.random_normal([2])),\n",
    "            'out': tf.Variable(tf.random_normal([num_classes])),\n",
    "            'b2': tf.Variable(tf.random_normal([2])),\n",
    "            'b3': tf.Variable(tf.random_normal([2]))\n",
    "        }\n",
    "\n",
    "        test_signals, test_freqs = make_batch_singleton(batch_size, SNRdB, N, m)\n",
    "        test_signals_pair = np.zeros((batch_size, m, 2))\n",
    "        test_signals_pair[:, :, 0] = np.real(test_signals)\n",
    "        test_signals_pair[:, :, 1] = np.imag(test_signals)\n",
    "        training_size = 500\n",
    "        dict = {}\n",
    "        for i in range(training_size):\n",
    "            batch_x, batch_y = make_batch_singleton(batch_size, SNRdB, N, m)\n",
    "            batch_x_pair = np.zeros((batch_size, m, 2))\n",
    "            batch_x_pair[:, :, 0] = np.real(batch_x)\n",
    "            batch_x_pair[:, :, 1] = np.imag(batch_x)\n",
    "            dict[i] = (batch_x_pair, batch_y)\n",
    "\n",
    "        def neural_net(x):\n",
    "            layer_1 = tf.add(tf.nn.conv1d(x, weights['h1'], 1, 'VALID'), biases['b1'])\n",
    "            hidden_1 = tf.nn.relu(layer_1)\n",
    "            layer_2 = tf.add(tf.nn.conv1d(hidden_1, weights['h2'], 1, 'VALID'), biases['b2'])\n",
    "            hidden_2 = tf.nn.relu(layer_2)\n",
    "            layer_3 = tf.add(tf.nn.conv1d(hidden_2, weights['h3'], 1, 'VALID'), biases['b3'])\n",
    "            hidden_3 = tf.nn.relu(layer_3)\n",
    "            hidden_3 = tf.reshape(hidden_3, [batch_size, -1])\n",
    "            out_layer = tf.matmul(hidden_3, weights['out']) + biases['out']\n",
    "            return out_layer\n",
    "\n",
    "        # Construct model\n",
    "        logits = neural_net(X)\n",
    "        prediction = tf.nn.softmax(logits)\n",
    "        losses, accuracies = [], []\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=Y))  \n",
    "        '''+ 0.01*tf.nn.l2_loss(weights['h1']) + 0.01*tf.nn.l2_loss(weights['h2']) + 0.01*tf.nn.l2_loss(weights['out']) \\\n",
    "        + 0.01*tf.nn.l2_loss(biases['b1']) + 0.01*tf.nn.l2_loss(biases['b2']) + 0.01*tf.nn.l2_loss(biases['out']) '''\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "        # Evaluate model\n",
    "        correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Start training\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Run the initializer\n",
    "            sess.run(init)\n",
    "\n",
    "            for step in range(1, num_iter + 1):\n",
    "                batch_x_pair, batch_y = dict[step % training_size]\n",
    "\n",
    "                # Run optimization op (backprop)\n",
    "                sess.run(train_op, feed_dict={X: batch_x_pair, Y: batch_y})\n",
    "                if step % 500 == 0:\n",
    "                    # Calculate batch loss and accuracy\n",
    "                    loss, acc, pred = sess.run([loss_op, accuracy, prediction], feed_dict={X: batch_x_pair,\n",
    "                                                                         Y: batch_y})\n",
    "\n",
    "                    #print(\"pred: \", [np.argmax(a) for a in pred[:8]])\n",
    "                    #print(\"act:\", [np.argmax(a) for a in batch_y[:8]])\n",
    "                    accuracies.append(acc)\n",
    "                    losses.append(loss)\n",
    "                    #print(\"snr: \", SNRdB)\n",
    "                    #print(\"Iter \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                    #      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                    #      \"{:.3f}\".format(acc))\n",
    "            print(\"Training Finished for snr=\", SNRdB)\n",
    "\n",
    "            nn_acc = sess.run(accuracy, feed_dict={X: test_signals_pair, Y: test_freqs})        \n",
    "            print(\"Testing Accuracy Neural:\", nn_acc)\n",
    "            kay_acc = kays_singleton_accuracy(test_signals, test_freqs, m)\n",
    "            print(\"Testing Accuracy Kay:\", kay_acc)\n",
    "            trial_nn.append(nn_acc)\n",
    "            trial_kay.append(kay_acc)\n",
    "    nn_accs.append(np.median(trial_nn))\n",
    "    kay_1s.append(np.mean(trial_kay))\n",
    "        \n",
    "np.save('./data/singleton/snrs', snrs)\n",
    "np.save('./data/singleton/nn_accs', nn_accs)\n",
    "np.save('./data/singleton/kay_accs', kay_1s)\n",
    "plt.plot(snrs, nn_accs, '--bo')\n",
    "plt.plot(snrs, kay_1s, '--ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Finished for layers= 1\n",
      "Testing Accuracy Neural: 0.902\n",
      "Training Finished for layers= 1\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for layers= 1\n",
      "Testing Accuracy Neural: 0.887\n",
      "Training Finished for layers= 1\n",
      "Testing Accuracy Neural: 0.89\n",
      "Training Finished for layers= 1\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for layers= 1\n",
      "Testing Accuracy Neural: 0.913\n",
      "Training Finished for layers= 1\n",
      "Testing Accuracy Neural: 0.877\n",
      "Training Finished for layers= 1\n",
      "Testing Accuracy Neural: 0.882\n",
      "Training Finished for layers= 1\n",
      "Testing Accuracy Neural: 0.566\n",
      "Training Finished for layers= 1\n",
      "Testing Accuracy Neural: 0.854\n",
      "Training Finished for layers= 3\n",
      "Testing Accuracy Neural: 0.913\n",
      "Training Finished for layers= 3\n",
      "Testing Accuracy Neural: 0.872\n",
      "Training Finished for layers= 3\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 3\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for layers= 3\n",
      "Testing Accuracy Neural: 0.816\n",
      "Training Finished for layers= 3\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 3\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 3\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 3\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for layers= 3\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for layers= 5\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 5\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 5\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for layers= 5\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for layers= 5\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 5\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 5\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 5\n",
      "Testing Accuracy Neural: 0.823\n",
      "Training Finished for layers= 5\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for layers= 5\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 7\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 7\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 7\n",
      "Testing Accuracy Neural: 0.829\n",
      "Training Finished for layers= 7\n",
      "Testing Accuracy Neural: 0.813\n",
      "Training Finished for layers= 7\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 7\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 7\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 7\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for layers= 7\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 7\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 9\n",
      "Testing Accuracy Neural: 0.816\n",
      "Training Finished for layers= 9\n",
      "Testing Accuracy Neural: 0.816\n",
      "Training Finished for layers= 9\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 9\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 9\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 9\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 9\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 9\n",
      "Testing Accuracy Neural: 0.875\n",
      "Training Finished for layers= 9\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for layers= 9\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 11\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 11\n",
      "Testing Accuracy Neural: 0.922\n",
      "Training Finished for layers= 11\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 11\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 11\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 11\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 11\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 11\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for layers= 11\n",
      "Testing Accuracy Neural: 0.468\n",
      "Training Finished for layers= 11\n",
      "Testing Accuracy Neural: 0.468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23bb8371390>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seeing num layers vs accuracy \n",
    "\n",
    "nn_accs = []\n",
    "layers = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "N = 27000 \n",
    "SNRdB = -8\n",
    "m = 300 \n",
    "\n",
    "learning_rate = 0.005\n",
    "num_iter = 8000\n",
    "batch_size = 1000\n",
    "\n",
    "test_signals, test_freqs = make_batch_singleton(batch_size, SNRdB, N, m)\n",
    "test_signals_pair = np.zeros((batch_size, m, 2))\n",
    "test_signals_pair[:, :, 0] = np.real(test_signals)\n",
    "test_signals_pair[:, :, 1] = np.imag(test_signals)\n",
    "training_size = 500\n",
    "\n",
    "dict = {}\n",
    "for i in range(training_size):\n",
    "    batch_x, batch_y = make_batch_singleton(batch_size, SNRdB, N, m)\n",
    "    batch_x_pair = np.zeros((batch_size, m, 2))\n",
    "    batch_x_pair[:, :, 0] = np.real(batch_x)\n",
    "    batch_x_pair[:, :, 1] = np.imag(batch_x)\n",
    "    dict[i] = (batch_x_pair, batch_y)\n",
    "\n",
    "for layer in layers:\n",
    "    \n",
    "    trial = []\n",
    "    for _ in range(10):\n",
    "\n",
    "        # Network Parameters\n",
    "        num_classes = 3\n",
    "\n",
    "        # tf Graph input\n",
    "        X = tf.placeholder(\"float\", [None, m, 2])\n",
    "        Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "        # Store layers weight & bias\n",
    "        weights = {i: tf.Variable(tf.random_normal([3, 2, 2])) for i in range(1, layer+1)}\n",
    "        weights[0] = tf.Variable(tf.random_normal([5, 2, 2]))\n",
    "        weights['out'] = tf.Variable(tf.random_normal([(m-4-(2*layer))*2, num_classes]))\n",
    "        biases = {i: tf.Variable(tf.random_normal([2])) for i in range(layer+1)}\n",
    "        biases['out'] = tf.Variable(tf.random_normal([num_classes]))\n",
    "\n",
    "\n",
    "        def neural_net(x):\n",
    "            layer_1 = tf.add(tf.nn.conv1d(x, weights[0], 1, 'VALID'), biases[0])\n",
    "            hidden_1 = tf.nn.relu(layer_1)\n",
    "            for i in range(1, layer+1):\n",
    "                layer_1 = tf.add(tf.nn.conv1d(hidden_1, weights[i], 1, 'VALID'), biases[i])\n",
    "                hidden_1 = tf.nn.relu(layer_1)\n",
    "            hidden_3 = tf.reshape(hidden_1, [batch_size, -1])\n",
    "            out_layer = tf.matmul(hidden_3, weights['out']) + biases['out']\n",
    "            return out_layer\n",
    "\n",
    "        # Construct model\n",
    "        logits = neural_net(X)\n",
    "        prediction = tf.nn.softmax(logits)\n",
    "        losses, accuracies = [], []\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=Y))  \n",
    "        '''+ 0.01*tf.nn.l2_loss(weights['h1']) + 0.01*tf.nn.l2_loss(weights['h2']) + 0.01*tf.nn.l2_loss(weights['out']) \\\n",
    "        + 0.01*tf.nn.l2_loss(biases['b1']) + 0.01*tf.nn.l2_loss(biases['b2']) + 0.01*tf.nn.l2_loss(biases['out']) '''\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "        # Evaluate model\n",
    "        correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Start training\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Run the initializer\n",
    "            sess.run(init)\n",
    "\n",
    "            for step in range(1, num_iter + 1):\n",
    "                batch_x_pair, batch_y = dict[step % training_size]\n",
    "\n",
    "                # Run optimization op (backprop)\n",
    "                sess.run(train_op, feed_dict={X: batch_x_pair, Y: batch_y})\n",
    "                if step % 500 == 0:\n",
    "                    # Calculate batch loss and accuracy\n",
    "                    loss, acc, pred = sess.run([loss_op, accuracy, prediction], feed_dict={X: batch_x_pair,\n",
    "                                                                         Y: batch_y})\n",
    "\n",
    "                    #print(\"pred: \", [np.argmax(a) for a in pred[:8]])\n",
    "                    #print(\"act:\", [np.argmax(a) for a in batch_y[:8]])\n",
    "                    accuracies.append(acc)\n",
    "                    losses.append(loss)\n",
    "                    #print(\"snr: \", SNRdB)\n",
    "                    #print(\"Iter \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                    #      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                    #      \"{:.3f}\".format(acc))\n",
    "            print(\"Training Finished for layers=\", layer)\n",
    "\n",
    "            nn_acc = sess.run(accuracy, feed_dict={X: test_signals_pair, Y: test_freqs})        \n",
    "            print(\"Testing Accuracy Neural:\", nn_acc)\n",
    "            trial.append(nn_acc)\n",
    "    nn_accs.append(np.median(trial))\n",
    "np.save('./data/singleton/layers', layers)\n",
    "np.save('./data/singleton/layer_accs', nn_accs)\n",
    "plt.plot(layers, nn_accs, '--bo')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Finished for dataset snr= -4\n",
      "Testing Accuracy Neural: 0.903\n",
      "Training Finished for dataset snr= -4\n",
      "Testing Accuracy Neural: 0.943\n",
      "Training Finished for dataset snr= -4\n",
      "Testing Accuracy Neural: 0.887\n",
      "Training Finished for dataset snr= -4\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for dataset snr= -4\n",
      "Testing Accuracy Neural: 0.93\n",
      "Training Finished for dataset snr= -4\n",
      "Testing Accuracy Neural: 0.442\n",
      "Training Finished for dataset snr= -4\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for dataset snr= -4\n",
      "Testing Accuracy Neural: 0.442\n",
      "Training Finished for dataset snr= -4\n",
      "Testing Accuracy Neural: 0.443\n",
      "Training Finished for dataset snr= -4\n",
      "Testing Accuracy Neural: 0.944\n",
      "Training Finished for dataset snr= -6\n",
      "Testing Accuracy Neural: 0.955\n",
      "Training Finished for dataset snr= -6\n",
      "Testing Accuracy Neural: 0.951\n",
      "Training Finished for dataset snr= -6\n",
      "Testing Accuracy Neural: 0.933\n",
      "Training Finished for dataset snr= -6\n",
      "Testing Accuracy Neural: 0.442\n",
      "Training Finished for dataset snr= -6\n",
      "Testing Accuracy Neural: 0.442\n",
      "Training Finished for dataset snr= -6\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for dataset snr= -6\n",
      "Testing Accuracy Neural: 0.934\n",
      "Training Finished for dataset snr= -6\n",
      "Testing Accuracy Neural: 0.442\n",
      "Training Finished for dataset snr= -6\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for dataset snr= -6\n",
      "Testing Accuracy Neural: 0.442\n",
      "Training Finished for dataset snr= -8\n",
      "Testing Accuracy Neural: 0.963\n",
      "Training Finished for dataset snr= -8\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for dataset snr= -8\n",
      "Testing Accuracy Neural: 0.9\n",
      "Training Finished for dataset snr= -8\n",
      "Testing Accuracy Neural: 0.936\n",
      "Training Finished for dataset snr= -8\n",
      "Testing Accuracy Neural: 0.444\n",
      "Training Finished for dataset snr= -8\n",
      "Testing Accuracy Neural: 0.375\n",
      "Training Finished for dataset snr= -8\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for dataset snr= -8\n",
      "Testing Accuracy Neural: 0.944\n",
      "Training Finished for dataset snr= -8\n",
      "Testing Accuracy Neural: 0.957\n",
      "Training Finished for dataset snr= -8\n",
      "Testing Accuracy Neural: 0.96\n",
      "Training Finished for dataset snr= -10\n",
      "Testing Accuracy Neural: 0.902\n",
      "Training Finished for dataset snr= -10\n",
      "Testing Accuracy Neural: 0.911\n",
      "Training Finished for dataset snr= -10\n",
      "Testing Accuracy Neural: 0.896\n",
      "Training Finished for dataset snr= -10\n",
      "Testing Accuracy Neural: 0.863\n",
      "Training Finished for dataset snr= -10\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for dataset snr= -10\n",
      "Testing Accuracy Neural: 0.375\n",
      "Training Finished for dataset snr= -10\n",
      "Testing Accuracy Neural: 0.864\n",
      "Training Finished for dataset snr= -10\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for dataset snr= -10\n",
      "Testing Accuracy Neural: 0.885\n",
      "Training Finished for dataset snr= -10\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for dataset snr= -12\n",
      "Testing Accuracy Neural: 0.957\n",
      "Training Finished for dataset snr= -12\n",
      "Testing Accuracy Neural: 0.959\n",
      "Training Finished for dataset snr= -12\n",
      "Testing Accuracy Neural: 0.935\n",
      "Training Finished for dataset snr= -12\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for dataset snr= -12\n",
      "Testing Accuracy Neural: 0.954\n",
      "Training Finished for dataset snr= -12\n",
      "Testing Accuracy Neural: 0.967\n",
      "Training Finished for dataset snr= -12\n",
      "Testing Accuracy Neural: 0.941\n",
      "Training Finished for dataset snr= -12\n",
      "Testing Accuracy Neural: 0.817\n",
      "Training Finished for dataset snr= -12\n",
      "Testing Accuracy Neural: 0.874\n",
      "Training Finished for dataset snr= -12\n",
      "Testing Accuracy Neural: 0.442\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seeing training on lower vs same snr\n",
    "\n",
    "nn_accs = []\n",
    "\n",
    "N = 27000 \n",
    "SNRdB = -6\n",
    "m = 300 \n",
    "\n",
    "learning_rate = 0.005\n",
    "num_iter = 8000\n",
    "batch_size = 1000\n",
    "\n",
    "test_signals, test_freqs = make_batch_singleton(batch_size, SNRdB, N, m)\n",
    "test_signals_pair = np.zeros((batch_size, m, 2))\n",
    "test_signals_pair[:, :, 0] = np.real(test_signals)\n",
    "test_signals_pair[:, :, 1] = np.imag(test_signals)\n",
    "\n",
    "snrs = [-4, -6, -8, -10, -12]\n",
    "\n",
    "for snr in snrs:\n",
    "\n",
    "    trial = []\n",
    "    for _ in range(10):\n",
    "        # Network Parameters\n",
    "        num_classes = 3\n",
    "\n",
    "        # tf Graph input\n",
    "        X = tf.placeholder(\"float\", [None, m, 2])\n",
    "        Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "        # Store layers weight & bias\n",
    "        weights = {\n",
    "            'h1': tf.Variable(tf.random_normal([5, 2, 2])), # filtersize, in channels, outchannels\n",
    "            'out': tf.Variable(tf.random_normal([(m-4-2-2)*2, num_classes])),\n",
    "            'h2': tf.Variable(tf.random_normal([3, 2, 2])),\n",
    "            'h3': tf.Variable(tf.random_normal([3, 2, 2]))\n",
    "        }\n",
    "        biases = {\n",
    "            'b1': tf.Variable(tf.random_normal([2])),\n",
    "            'out': tf.Variable(tf.random_normal([num_classes])),\n",
    "            'b2': tf.Variable(tf.random_normal([2])),\n",
    "            'b3': tf.Variable(tf.random_normal([2]))\n",
    "        }\n",
    "\n",
    "        dict = {}\n",
    "        training_size = 500\n",
    "        for i in range(training_size):\n",
    "            batch_x, batch_y = make_batch_singleton(batch_size, snr, N, m)\n",
    "            batch_x_pair = np.zeros((batch_size, m, 2))\n",
    "            batch_x_pair[:, :, 0] = np.real(batch_x)\n",
    "            batch_x_pair[:, :, 1] = np.imag(batch_x)\n",
    "            dict[i] = (batch_x_pair, batch_y)\n",
    "\n",
    "        def neural_net(x):\n",
    "            layer_1 = tf.add(tf.nn.conv1d(x, weights['h1'], 1, 'VALID'), biases['b1'])\n",
    "            hidden_1 = tf.nn.relu(layer_1)\n",
    "            layer_2 = tf.add(tf.nn.conv1d(hidden_1, weights['h2'], 1, 'VALID'), biases['b2'])\n",
    "            hidden_2 = tf.nn.relu(layer_2)\n",
    "            layer_3 = tf.add(tf.nn.conv1d(hidden_2, weights['h3'], 1, 'VALID'), biases['b3'])\n",
    "            hidden_3 = tf.nn.relu(layer_3)\n",
    "            hidden_3 = tf.reshape(hidden_3, [batch_size, -1])\n",
    "            out_layer = tf.matmul(hidden_3, weights['out']) + biases['out']\n",
    "            return out_layer\n",
    "\n",
    "        # Construct model\n",
    "        logits = neural_net(X)\n",
    "        prediction = tf.nn.softmax(logits)\n",
    "        losses, accuracies = [], []\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=Y))  \n",
    "        '''+ 0.01*tf.nn.l2_loss(weights['h1']) + 0.01*tf.nn.l2_loss(weights['h2']) + 0.01*tf.nn.l2_loss(weights['out']) \\\n",
    "        + 0.01*tf.nn.l2_loss(biases['b1']) + 0.01*tf.nn.l2_loss(biases['b2']) + 0.01*tf.nn.l2_loss(biases['out']) '''\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "        # Evaluate model\n",
    "        correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Start training\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Run the initializer\n",
    "            sess.run(init)\n",
    "\n",
    "            for step in range(1, num_iter + 1):\n",
    "                batch_x_pair, batch_y = dict[step % training_size]\n",
    "\n",
    "                # Run optimization op (backprop)\n",
    "                sess.run(train_op, feed_dict={X: batch_x_pair, Y: batch_y})\n",
    "                if step % 500 == 0:\n",
    "                    # Calculate batch loss and accuracy\n",
    "                    loss, acc, pred = sess.run([loss_op, accuracy, prediction], feed_dict={X: batch_x_pair,\n",
    "                                                                         Y: batch_y})\n",
    "\n",
    "                    #print(\"pred: \", [np.argmax(a) for a in pred[:8]])\n",
    "                    #print(\"act:\", [np.argmax(a) for a in batch_y[:8]])\n",
    "                    accuracies.append(acc)\n",
    "                    losses.append(loss)\n",
    "                    #print(\"snr: \", SNRdB)\n",
    "                    #print(\"Iter \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                    #      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                    #      \"{:.3f}\".format(acc))\n",
    "            print(\"Training Finished for dataset snr=\", snr)\n",
    "\n",
    "            nn_acc = sess.run(accuracy, feed_dict={X: test_signals_pair, Y: test_freqs})        \n",
    "            print(\"Testing Accuracy Neural:\", nn_acc)\n",
    "            trial.append(nn_acc)\n",
    "    nn_accs.append(np.median(trial))\n",
    "np.save('./data/singleton/snrs_training', snrs)\n",
    "np.save('./data/singleton/nn_accs_snrs_training', nn_accs)\n",
    "plt.plot(snrs, nn_accs, '--bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy Neural: 0.036\n",
      "Testing Accuracy Neural: 0.04\n",
      "Testing Accuracy Neural: 0.06\n"
     ]
    }
   ],
   "source": [
    "#cnn binary\n",
    "\n",
    "nn_accs = []\n",
    "kay_accs = []\n",
    "\n",
    "N = 512\n",
    "SNRdB = 5\n",
    "m = 32\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.005\n",
    "num_iter = 8000\n",
    "batch_size = 500\n",
    "\n",
    "# Network Parameters\n",
    "num_classes = math.ceil(np.log2(N))\n",
    "\n",
    "layers = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "training_size = 1000\n",
    "dict = {}\n",
    "for i in range(training_size):\n",
    "    batch_x, batch_y, _ = make_batch_noisy(batch_size, SNRdB, N, m, True)\n",
    "    batch_x_pair = np.zeros((batch_size, m, 2))\n",
    "    batch_x_pair[:, :, 0] = np.real(batch_x)\n",
    "    batch_x_pair[:, :, 1] = np.imag(batch_x)\n",
    "    dict[i] = (batch_x_pair, batch_y)\n",
    "    \n",
    "test_signals, test_freqs, test_freqs_onehot = make_batch_noisy(batch_size, SNRdB, N, m, True)\n",
    "test_signals_pair = np.zeros((batch_size, m, 2))\n",
    "test_signals_pair[:, :, 0] = np.real(test_signals)\n",
    "test_signals_pair[:, :, 1] = np.imag(test_signals)\n",
    "\n",
    "\n",
    "for layer in layers:\n",
    "\n",
    "    trial = []\n",
    "    for _ in range(10):\n",
    "\n",
    "        # tf Graph input\n",
    "        X = tf.placeholder(\"float\", [None, m, 2])\n",
    "        Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "        # Store layers weight & bias\n",
    "\n",
    "\n",
    "\n",
    "        # Store layers weight & bias\n",
    "        weights = {i: tf.Variable(tf.random_normal([3, 2, 2])) for i in range(1, layer+1)}\n",
    "        weights[0] = tf.Variable(tf.random_normal([5, 2, 2]))\n",
    "        weights['out'] = tf.Variable(tf.random_normal([(m-4-(2*layer))*2, num_classes]))\n",
    "        biases = {i: tf.Variable(tf.random_normal([2])) for i in range(layer+1)}\n",
    "        biases['out'] = tf.Variable(tf.random_normal([num_classes]))\n",
    "\n",
    "\n",
    "        def neural_net(x):\n",
    "            layer_1 = tf.add(tf.nn.conv1d(x, weights[0], 1, 'VALID'), biases[0])\n",
    "            hidden_1 = tf.nn.relu(layer_1)\n",
    "            for i in range(1, layer+1):\n",
    "                layer_1 = tf.add(tf.nn.conv1d(hidden_1, weights[i], 1, 'VALID'), biases[i])\n",
    "                hidden_1 = tf.nn.relu(layer_1)\n",
    "            hidden_3 = tf.reshape(hidden_1, [batch_size, -1])\n",
    "            out_layer = tf.matmul(hidden_3, weights['out']) + biases['out']\n",
    "            return out_layer\n",
    "\n",
    "\n",
    "        # Construct model\n",
    "        logits = neural_net(X)\n",
    "        prediction = tf.round(tf.nn.sigmoid(logits))\n",
    "        losses, accuracies = [], []\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=logits, labels=Y))  \n",
    "        ''' + 0.01*tf.nn.l2_loss(weights['h1']) + 0.01*tf.nn.l2_loss(weights['h2']) + 0.01*tf.nn.l2_loss(weights['out'])\\\n",
    "        + 0.01*tf.nn.l2_loss(biases['b1']) + 0.01*tf.nn.l2_loss(biases['b2']) + 0.01*tf.nn.l2_loss(biases['out'])'''\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "        correct_pred = tf.equal(prediction, Y)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "        # Initialize the variables (i.e. assign their default value)\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Start training\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            # Run the initializer\n",
    "            sess.run(init)\n",
    "\n",
    "            for step in range(1, num_iter + 1):\n",
    "                batch_x_pair, batch_y = dict[step % training_size]\n",
    "\n",
    "                # Run optimization op (backprop)\n",
    "                sess.run(train_op, feed_dict={X: batch_x_pair, Y: batch_y})\n",
    "                if step % 100 == 0:\n",
    "                    # Calculate batch loss and accuracy\n",
    "                    loss, pred = sess.run([loss_op, prediction], feed_dict={X: batch_x_pair,\n",
    "                                                                         Y: batch_y})\n",
    "                    losses.append(loss)\n",
    "                '''if step % 50000 == 0:\n",
    "                    pred = sess.run(prediction, feed_dict={X: batch_x_pair,\n",
    "                                                                         Y: batch_y})\n",
    "                    preds = [binary_to_int(a).eval() for a in pred]\n",
    "                    acts = [binary_to_int(a).eval() for a in batch_y]\n",
    "                    print('batch accuracy: ', np.mean(np.equal(preds, acts)))\n",
    "                    pred = sess.run(prediction, feed_dict={X: test_signals_pair, Y: test_freqs})\n",
    "                    preds = [binary_to_int(a).eval() for a in pred]\n",
    "                    acts = [binary_to_int(a).eval() for a in test_freqs]\n",
    "                    print('test accuracy: ', np.mean(np.equal(preds, acts)))'''\n",
    "\n",
    "            #print(\"Training Finished\")\n",
    "\n",
    "            loss, nn_acc, pred = sess.run([loss_op, accuracy, prediction], feed_dict={X: test_signals_pair, Y: test_freqs})\n",
    "            #loss, nn_acc, pred = sess.run([loss_op, accuracy, prediction], feed_dict={X: full_sig_pair, Y: full_bin})\n",
    "            #hammings = [hamming(a, b) for a, b in zip(pred, test_freqs)]\n",
    "            #hamming_list.append(hammings)\n",
    "            #print(np.mean(hammings))\n",
    "            #plt.hist(hammings)\n",
    "            #plt.show()\n",
    "            preds = [binary_to_int(a).eval() for a in pred]\n",
    "            acts = [binary_to_int(a).eval() for a in test_freqs] \n",
    "            nn_acc = np.mean(np.equal(preds, acts))\n",
    "\n",
    "            #kay_acc = test_kays(test_signals, test_freqs, N)\n",
    "\n",
    "            print(\"Testing Accuracy Neural:\", nn_acc)\n",
    "\n",
    "            #print(\"Testing Accuracy Kay:\", kay_acc)\n",
    "            trial.append(nn_acc)\n",
    "            #kay_accs.append(kay_acc)\n",
    "    nn_accs.append(np.median(trial))\n",
    "np.save('./data/singleton/freq_layers', layers)\n",
    "np.save('./data/singleton/freq_accs_layers', nn_accs)\n",
    "plt.plot(layers, nn_accs, '--bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
